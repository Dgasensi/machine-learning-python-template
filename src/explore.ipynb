{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importamos modulos necesarios\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import statsmodels.api as sm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Escalar\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# optimizar\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "from skopt import BayesSearchCV\n",
    "# Metricas de error\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "'''import missingno as msno\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder\n",
    "import joblib\n",
    "FunctionTransformer, \n",
    "''' \n",
    "# Para eliminar un mensaje de alerta de pandas relacionado con la copia de un dataframe\n",
    "pd.options.mode.copy_on_write = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-73.97</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75</td>\n",
       "      <td>-73.98</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                name  host_id host_name  \\\n",
       "0  2539  Clean & quiet apt home by the park     2787      John   \n",
       "1  2595               Skylit Midtown Castle     2845  Jennifer   \n",
       "\n",
       "  neighbourhood_group neighbourhood  latitude  longitude        room_type  \\\n",
       "0            Brooklyn    Kensington     40.65     -73.97     Private room   \n",
       "1           Manhattan       Midtown     40.75     -73.98  Entire home/apt   \n",
       "\n",
       "   price  minimum_nights  number_of_reviews last_review  reviews_per_month  \\\n",
       "0    149               1                  9  2018-10-19               0.21   \n",
       "1    225               1                 45  2019-05-21               0.38   \n",
       "\n",
       "   calculated_host_listings_count  availability_365  \n",
       "0                               6               365  \n",
       "1                               2               355  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48893</th>\n",
       "      <td>36485609</td>\n",
       "      <td>43rd St. Time Square-cozy single bed</td>\n",
       "      <td>30985759</td>\n",
       "      <td>Taz</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>40.76</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>Shared room</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48894</th>\n",
       "      <td>36487245</td>\n",
       "      <td>Trendy duplex in the very heart of Hell's Kitchen</td>\n",
       "      <td>68119814</td>\n",
       "      <td>Christophe</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>40.76</td>\n",
       "      <td>-73.99</td>\n",
       "      <td>Private room</td>\n",
       "      <td>90</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                               name   host_id  \\\n",
       "48893  36485609               43rd St. Time Square-cozy single bed  30985759   \n",
       "48894  36487245  Trendy duplex in the very heart of Hell's Kitchen  68119814   \n",
       "\n",
       "        host_name neighbourhood_group   neighbourhood  latitude  longitude  \\\n",
       "48893         Taz           Manhattan  Hell's Kitchen     40.76     -73.99   \n",
       "48894  Christophe           Manhattan  Hell's Kitchen     40.76     -73.99   \n",
       "\n",
       "          room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "48893   Shared room     55               1                  0         NaN   \n",
       "48894  Private room     90               7                  0         NaN   \n",
       "\n",
       "       reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "48893                NaN                               6                 2  \n",
       "48894                NaN                               1                23  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importamos el dataset\n",
    "df = pd.read_csv('AB_NYC_2019.csv')\n",
    "# Mostramos todas las columnas\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Visualizacion de la estructura general // primer analisis\n",
    "display(df.head(2))\n",
    "display(df.tail(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "      <th>nulls</th>\n",
       "      <th>percent_nulls</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>total_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>48895</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>47905</td>\n",
       "      <td>16</td>\n",
       "      <td>0.03</td>\n",
       "      <td>object</td>\n",
       "      <td>48879</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_id</th>\n",
       "      <td>37457</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>host_name</th>\n",
       "      <td>11452</td>\n",
       "      <td>21</td>\n",
       "      <td>0.04</td>\n",
       "      <td>object</td>\n",
       "      <td>48874</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood</th>\n",
       "      <td>221</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>19048</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>14718</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>394</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>last_review</th>\n",
       "      <td>1764</td>\n",
       "      <td>10052</td>\n",
       "      <td>20.56</td>\n",
       "      <td>object</td>\n",
       "      <td>38843</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews_per_month</th>\n",
       "      <td>937</td>\n",
       "      <td>10052</td>\n",
       "      <td>20.56</td>\n",
       "      <td>float64</td>\n",
       "      <td>38843</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_365</th>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>48895</td>\n",
       "      <td>48895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                nunique  nulls  percent_nulls    Dtype  \\\n",
       "id                                48895      0           0.00    int64   \n",
       "name                              47905     16           0.03   object   \n",
       "host_id                           37457      0           0.00    int64   \n",
       "host_name                         11452     21           0.04   object   \n",
       "neighbourhood_group                   5      0           0.00   object   \n",
       "neighbourhood                       221      0           0.00   object   \n",
       "latitude                          19048      0           0.00  float64   \n",
       "longitude                         14718      0           0.00  float64   \n",
       "room_type                             3      0           0.00   object   \n",
       "price                               674      0           0.00    int64   \n",
       "minimum_nights                      109      0           0.00    int64   \n",
       "number_of_reviews                   394      0           0.00    int64   \n",
       "last_review                        1764  10052          20.56   object   \n",
       "reviews_per_month                   937  10052          20.56  float64   \n",
       "calculated_host_listings_count       47      0           0.00    int64   \n",
       "availability_365                    366      0           0.00    int64   \n",
       "\n",
       "                                non_null  total_values  \n",
       "id                                 48895         48895  \n",
       "name                               48879         48895  \n",
       "host_id                            48895         48895  \n",
       "host_name                          48874         48895  \n",
       "neighbourhood_group                48895         48895  \n",
       "neighbourhood                      48895         48895  \n",
       "latitude                           48895         48895  \n",
       "longitude                          48895         48895  \n",
       "room_type                          48895         48895  \n",
       "price                              48895         48895  \n",
       "minimum_nights                     48895         48895  \n",
       "number_of_reviews                  48895         48895  \n",
       "last_review                        38843         48895  \n",
       "reviews_per_month                  38843         48895  \n",
       "calculated_host_listings_count     48895         48895  \n",
       "availability_365                   48895         48895  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dtype\n",
       "int64      7\n",
       "object     6\n",
       "float64    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe tiene 48895 filas y 16 columnas\n",
      "Hay 0 valores duplicados\n"
     ]
    }
   ],
   "source": [
    "# Cargo mi funcion personal de practica // informacion agrupada de los dataframes\n",
    "def df_info(df):\n",
    "    df_info = pd.DataFrame({\n",
    "        'nunique': df.nunique(),\n",
    "        'nulls': df.isnull().sum(),\n",
    "        'percent_nulls' : df.isnull().mean()*100,\n",
    "        'Dtype': df.dtypes,\n",
    "        'non_null': df.count(),\n",
    "        'total_values': len(df)  \n",
    "    })\n",
    "    types_counter = df_info['Dtype'].value_counts()\n",
    "    duplicated = df.duplicated().sum()\n",
    "    display(df_info, types_counter)\n",
    "    print(f'El dataframe tiene {df.shape[0]} filas y {df.shape[1]} columnas')\n",
    "    print(f'Hay {duplicated} valores duplicados')\n",
    "\n",
    "# Llamo a la funcion y buscamos nulos y duplicados\n",
    "df_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tenemos 6 columnas categoricas que habra que analizar. En caso de que  tengan valor predictivo buscaremos el mejor metodo para codificarlas.\n",
    "\n",
    "- Las columnas last_review, reviews_per_month, name y host name tienen valores nulos.\n",
    "\n",
    "- No hay ninguna columna binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos dos variables categoricas que carecen de valor predictivo para este caso y tienen valores nulos // \n",
    "df.drop(['name','host_name'],  axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La variable 'name' si que seria interesante para otro tipo de analisis mas complejo en el que se tuviesen en cuenta las palabras utilizadas para describir el anuncio y como éstas influyen en la demanda de las habitaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear un diagrama de dispersión múltiple para visualizar dos columnas que dudo si eliminar o no\n",
    "fig, axis = plt.subplots(2, 2, figsize = (7, 4))\n",
    "\n",
    "\n",
    "# Crear un diagrama de dispersión múltiple para visualizar dos columnas que dudo si eliminar o no\n",
    "sns.regplot(ax = axis[0, 0], data = df, x = 'id', y = \"price\")\n",
    "sns.heatmap(df[[\"price\", \"id\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 0], cbar = False)\n",
    "sns.regplot(ax = axis[0, 1], data = df, x = \"host_id\", y = \"price\").set(ylabel=None)\n",
    "sns.heatmap(df[[\"price\", \"host_id\"]].corr(), annot = True, fmt = \".2f\", ax = axis[1, 1])\n",
    "\n",
    "# Ajustar el layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar el plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin apenas correlacion y muchos valores nulos. // se eliminan host_id y id, ademas de last_review', 'reviews_per_month que tiene un 20% de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neighbourhood_group               0\n",
       "neighbourhood                     0\n",
       "latitude                          0\n",
       "longitude                         0\n",
       "room_type                         0\n",
       "price                             0\n",
       "minimum_nights                    0\n",
       "number_of_reviews                 0\n",
       "calculated_host_listings_count    0\n",
       "availability_365                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos columnas irrelevantes\n",
    "df.drop(['last_review', 'reviews_per_month', 'id', 'host_id'],  axis=1, inplace=True)\n",
    "# Comprobamos que ya no hay valores faltantes\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas 'last_review', 'reviews_per_month' contienen un 20% de valores faltantes. Descarto imputarlos ya que:\n",
    "\n",
    "- En primer lugar intuyo que no tienen un alto valor predictivo\n",
    "\n",
    "- En segundo lugar, contamos con la columna 'number_of_reviews' que contiene el mismo tipo de información\n",
    "\n",
    "- Teniendo en cuenta los dos puntos anteriores no veo acertado añadir ruido al modelo y se eliminan.\n",
    "\n",
    "Las columnas 'id' y 'host_id' son valores de identificacion y  en su mayoria valores unicos. No añaden informacion a las caracteristicas de las habitaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos precios iguales o menores a 0\n",
    "df = df[df['price'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Crear un grid para dos plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Histograma de precios\n",
    "ax[0].hist(df['price'], bins=20, color='skyblue', edgecolor='black')\n",
    "ax[0].set_title('Precios de las habitaciones')\n",
    "ax[0].set_xlabel('Precio')\n",
    "ax[0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Boxplot de precios\n",
    "ax[1].boxplot(df['price'], vert=False)\n",
    "ax[1].set_title('Distribucion de precios')\n",
    "ax[1].set_xlabel('Precio')\n",
    "\n",
    "# Mostrar la figura\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nos encontramos con una distribucion de precios extremadamente sesgada a la derecha que intentaremos normalizar en la siguiente linea de codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una nueva columna aplicando un logaritmo natural a la columna 'price' que nos proporcionara una distribución de valores mas normalizada\n",
    "df['LOG_PRICE'] = np.log(df.price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grid para dos plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Histograma de distribucion de frecuencia de precios\n",
    "ax[0].hist(df['LOG_PRICE'], bins=20, color='skyblue', edgecolor='black')\n",
    "ax[0].set_title('Histograma del precio')\n",
    "ax[0].set_xlabel('Precio')\n",
    "ax[0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Boxplot de distribucion de precios\n",
    "ax[1].boxplot(df['LOG_PRICE'], vert=False)\n",
    "ax[1].set_title('Boxplot del precio')\n",
    "ax[1].set_xlabel('Precio')\n",
    "# Mostrar la figura\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tenemos una distribucion mas normalizada despues de aplicar el logaritmo a la columna precios, no obstante se aprecia que la grafica esta sesgada a derecha.\n",
    "- En el boxplot tambien se aprecia el sesgo a derecha y multiples outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>LOG_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-73.97</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group neighbourhood  latitude  longitude     room_type  \\\n",
       "0            Brooklyn    Kensington     40.65     -73.97  Private room   \n",
       "\n",
       "   minimum_nights  number_of_reviews  calculated_host_listings_count  \\\n",
       "0               1                  9                               6   \n",
       "\n",
       "   availability_365  LOG_PRICE  \n",
       "0               365       5.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Eliminamos la columna price para que no lleve a confusion. Solo hay que tener en cuenta aplicar la exponencial al resultado final para que de el valor en el formato original\n",
    "df.drop('price', axis=1, inplace=True)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedemos con la busqueda de datos atipicos en las variables cuantitativas\n",
    "\n",
    "# Variables independientes  y dependiente + eliminacion de variables categoricas\n",
    "X = df.drop(['neighbourhood_group','neighbourhood','room_type', 'LOG_PRICE'], axis=1)\n",
    "y = df['LOG_PRICE']\n",
    "\n",
    "# modelo ordinary least squares para aplicarle el metodo  get_influence().cooks_distance\n",
    "X = sm.add_constant(np.asarray(X))\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Obtenemos la distancia de cook para las observaciones\n",
    "cooks_distance = model.get_influence().cooks_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficamos el resultado de cooks_distance\n",
    "plt.scatter(df.LOG_PRICE, cooks_distance[0], s=1)\n",
    "plt.xlabel('precio')\n",
    "plt.ylabel('Cooks Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2160\n"
     ]
    }
   ],
   "source": [
    "# Buscamos la distancia de cook optima\n",
    "optimal_cooks_distance = 4/len(cooks_distance[0])\n",
    "optimal_cooks_data = np.where(cooks_distance[0]>= optimal_cooks_distance)\n",
    "# Cantidad de terminos a eliminar\n",
    "print(optimal_cooks_data[0].size)\n",
    "# Siguiendo la regla de 4/n para la distancia de cook optima eliminamos 2160 filas  (4.41%) de los datos\n",
    "df.drop(optimal_cooks_data[0], axis=0, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAHqCAYAAAAZLi26AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAABgDElEQVR4nO3deZzN9f////s5M2bfMGbDaDAxluxFWbMvRZsWZE3LIBSlJKSEFiKkxVJU6lvqbZ9UKknWsgzGUjPFDJNlzGLGzHn9/vCb83HMCOO8nGbmdr1cziXn9Xq+nq/H68jree7ntVkMwzAEAAAAAACczurqAgAAAAAAKKkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdgEluuOEG9evXz9VllErX8tlbLBaNHz/eqfVcD61bt1br1q1dXQYA4AKuHlP69eunG264oUjLFtdxZfz48bJYLK4uA3BA6AauwIIFC2SxWLRly5ZC57du3Vp16tS55vWsXLmyWAY+AACup/xx+cJXSEiI2rRpo1WrVrm6vGu2Z88ejR8/Xn/88YerSwHgBIRuwCT79u3Tu+++e1XLrFy5UhMmTDCpIpRka9eu1dq1a11dBgBcVxMnTtSHH36oRYsWafTo0Tp+/Li6dOmi5cuXu7q0a7Jnzx5NmDCB0F0EY8eOVVZWlqvLABy4u7oAoKTy9PR0dQlXLSMjQ76+vq4uo8TLzMyUj4+PU/v08PBwan8AUBx07txZjRs3tr8fOHCgQkND9fHHH6tbt24urAxXwozvHe7u7nJ3J+Lgv4Uj3YBJLr6u+Ny5c5owYYKio6Pl5eWl8uXLq3nz5oqLi5N0/rqrt99+W5IcTpfLl5GRoaeeekqVK1eWp6enatSooddee02GYTisNysrS8OGDVNwcLD8/f1155136u+//y5wXVn+NU979uzRQw89pLJly6p58+aSpN9//139+vVT1apV5eXlpbCwMA0YMED//POPw7ry+9i/f7969+6twMBAVahQQS+88IIMw1BSUpK6d++ugIAAhYWF6fXXX3dYPicnR+PGjVOjRo0UGBgoX19ftWjRQt99990VfcaGYWjSpEmqVKmSfHx81KZNG+3evbvQtqdOndLw4cPtn1/16tU1ZcoU2Wy2K1rXhb7//ntZLBZ9+umneu655xQWFiZfX1/deeedSkpKcmibf+nB1q1b1bJlS/n4+Oi5556TJGVnZ+vFF19U9erV5enpqcqVK2v06NHKzs4usM6PPvpIN998s3x8fFS2bFm1bNnS4ch2YdfeHTt2zP4F1MvLS/Xq1dPChQuvensBoLgICgqSt7d3gdB1uTE0KytLNWvWVM2aNR2Okp44cULh4eG69dZblZeXJ+n8eO3n56dDhw6pY8eO8vX1VUREhCZOnFhgTC7M9u3b1blzZwUEBMjPz09t27bVL7/8Yp+/YMEC3XfffZKkNm3a2L8PfP/99//a77Jly1SnTh15eXmpTp06+vLLLwttZ7PZNH36dNWuXVteXl4KDQ3Vo48+qpMnT1629sJYLBYNGTJEixcvVo0aNeTl5aVGjRrphx9+cGj3b987pPPjXKNGjeTt7a1y5crpgQceKDCmStKmTZvUpUsXlS1bVr6+vrrppps0Y8aMAuu5UG5url566SVVq1ZNnp6euuGGG/Tcc88VOt4CZuBnIOAqnD59WqmpqQWmnzt37rLLjh8/XpMnT9agQYN08803Ky0tTVu2bNG2bdvUvn17Pfroozpy5Iji4uL04YcfOixrGIbuvPNOfffddxo4cKDq16+vNWvWaNSoUfr777/15ptv2tv269dPS5cuVZ8+fdS0aVOtX79eXbt2vWRd9913n6Kjo/XKK6/YvyzExcXp0KFD6t+/v8LCwrR7927NmzdPu3fv1i+//FJgMLv//vsVExOjV199VStWrNCkSZNUrlw5vfPOO7r99ts1ZcoULV68WE8//bSaNGmili1bSpLS0tL03nvv6cEHH9QjjzyiM2fO6P3331fHjh3166+/qn79+v/6mY4bN06TJk1Sly5d1KVLF23btk0dOnRQTk6OQ7vMzEy1atVKf//9tx599FFFRkbq559/1pgxY3T06FFNnz79cn99hXr55ZdlsVj0zDPP6NixY5o+fbratWunHTt2yNvb297un3/+UefOnfXAAw+od+/eCg0Nlc1m05133qmffvpJgwcPVkxMjHbu3Kk333xT+/fv17Jly+zLT5gwQePHj9ett96qiRMnysPDQ5s2bdK3336rDh06FFpbVlaWWrdurQMHDmjIkCGKiorSZ599pn79+unUqVN68skni7TNAPBfkj8uG4ahY8eOaebMmUpPT1fv3r3tba5kDPX29tbChQt122236fnnn9cbb7whSYqNjdXp06e1YMECubm52fvMy8tTp06d1LRpU02dOlWrV6/Wiy++qNzcXE2cOPGS9e7evVstWrRQQECARo8erTJlyuidd95R69attX79et1yyy1q2bKlhg0bprfeekvPPfecYmJiJMn+38KsXbtW99xzj2rVqqXJkyfrn3/+Uf/+/VWpUqUCbR999FEtWLBA/fv317Bhw3T48GHNmjVL27dv14YNG1SmTJmr/ntYv369Pv30Uw0bNkyenp6aPXu2OnXqpF9//bXAPW8K+97x8ssv64UXXlDPnj01aNAgHT9+XDNnzlTLli21fft2BQUFSTr//aRbt24KDw/Xk08+qbCwMMXHx2v58uX/Oq4NGjRICxcu1L333qunnnpKmzZt0uTJkxUfH3/JHycApzIAXNb8+fMNSf/6ql27tsMyVapUMfr27Wt/X69ePaNr167/up7Y2FijsH+Wy5YtMyQZkyZNcph+7733GhaLxThw4IBhGIaxdetWQ5IxfPhwh3b9+vUzJBkvvviifdqLL75oSDIefPDBAuvLzMwsMO3jjz82JBk//PBDgT4GDx5sn5abm2tUqlTJsFgsxquvvmqffvLkScPb29vhM8nNzTWys7Md1nPy5EkjNDTUGDBgQIEaLnTs2DHDw8PD6Nq1q2Gz2ezTn3vuOUOSw3peeuklw9fX19i/f79DH88++6zh5uZmJCYm2qdd/DkV5rvvvjMkGRUrVjTS0tLs05cuXWpIMmbMmGGf1qpVK0OSMXfuXIc+PvzwQ8NqtRo//vijw/S5c+cakowNGzYYhmEYCQkJhtVqNe666y4jLy/Poe2F292qVSujVatW9vfTp083JBkfffSRfVpOTo7RrFkzw8/Pz6FuAChuLjUue3p6GgsWLHBoe6VjqGEYxpgxYwyr1Wr88MMPxmeffWZIMqZPn+6wXN++fQ1JxtChQ+3TbDab0bVrV8PDw8M4fvy4ffrFY0qPHj0MDw8P4+DBg/ZpR44cMfz9/Y2WLVvap+Wv+7vvvruiz6N+/fpGeHi4cerUKfu0tWvXGpKMKlWq2Kf9+OOPhiRj8eLFDsuvXr26wPSLx5VLyf/st2zZYp/2559/Gl5eXsZdd91ln3ap7x1//PGH4ebmZrz88ssO03fu3Gm4u7vbp+fm5hpRUVFGlSpVjJMnTzq0vXA8zF9Pvh07dhiSjEGDBjks8/TTTxuSjG+//fay2whcK04vB67C22+/rbi4uAKvm2666bLLBgUFaffu3UpISLjq9a5cuVJubm4aNmyYw/SnnnpKhmHY79S6evVqSdITTzzh0G7o0KGX7Puxxx4rMO3Co7Rnz55VamqqmjZtKknatm1bgfaDBg2y/9nNzU2NGzeWYRgaOHCgfXpQUJBq1KihQ4cOObTNvxbZZrPpxIkTys3NVePGjQtdz4W++eYb5eTkaOjQoQ5H3ocPH16g7WeffaYWLVqobNmySk1Ntb/atWunvLy8AqfAXamHH35Y/v7+9vf33nuvwsPDtXLlSod2np6e6t+/f4GaYmJiVLNmTYeabr/9dkmyn2K/bNky2Ww2jRs3Tlar4y773x6JsnLlSoWFhenBBx+0TytTpoyGDRum9PR0rV+/vkjbDAD/JReOyx999JHatGmjQYMG6YsvvrC3udIxVDp/Vlrt2rXVt29fPfHEE2rVqlWB5fINGTLE/uf8U6xzcnL0zTffFNo+Ly9Pa9euVY8ePVS1alX79PDwcD300EP66aeflJaWdtWfwdGjR7Vjxw717dtXgYGB9unt27dXrVq1HNp+9tlnCgwMVPv27R3GnkaNGsnPz++KL++6WLNmzdSoUSP7+8jISHXv3l1r1qyxn5af7+LvHV988YVsNpt69uzpUFNYWJiio6PtNW3fvl2HDx/W8OHD7Ue+811uPJSkkSNHOkx/6qmnJEkrVqy4uo0FioDTy4GrcPPNNzvcsCVffpj7NxMnTlT37t114403qk6dOurUqZP69OlzRYH9zz//VEREhEPAk/7vVLM///zT/l+r1aqoqCiHdtWrV79k3xe3lc5fwzZhwgR98sknOnbsmMO806dPF2gfGRnp8D4wMFBeXl4KDg4uMP3i68IXLlyo119/XXv37nU4Tb+wui6Uv83R0dEO0ytUqKCyZcs6TEtISNDvv/+uChUqFNrXxdt4pS5et8ViUfXq1QvcbbZixYoFbnSWkJCg+Pj4y9Z08OBBWa3WAl+cLufPP/9UdHR0gaB+8f8zAFCcXTwuP/jgg2rQoIGGDBmibt26ycPD44rHUOn8TSk/+OADNWnSRF5eXpo/f36hgc5qtToEZ0m68cYbJemSdxw/fvy4MjMzVaNGjQLzYmJiZLPZlJSUpNq1a1/Zxv//LjUeSlKNGjUcfsROSEjQ6dOnFRISUmhfzhoPpfOfR2Zmpo4fP66wsDD79IvH94SEBBmGUWgfkuynux88eFCSrvoRrfnfjS7+LhQWFqagoCDGQ1wXhG7gOmnZsqUOHjyor776SmvXrtV7772nN998U3PnznU4Uny9XXhUO1/Pnj31888/a9SoUapfv778/Pxks9nUqVOnQm88duF1bv82TZLDTWY++ugj9evXTz169NCoUaMUEhIiNzc3TZ482T64OoPNZlP79u01evToQufnf1EyS2Gfsc1mU926de3XDV6scuXKptYEACWR1WpVmzZtNGPGDCUkJFx1gJWkNWvWSDp/pldCQsJlfwQuTmw2m0JCQrR48eJC51/qh2BnunhMtNlsslgsWrVqVaHfHfz8/Jyy3n87Gg6YjdANXEflypVT//791b9/f6Wnp6tly5YaP368PXRfakCoUqWKvvnmG505c8bhl/q9e/fa5+f/12az6fDhww6/GB84cOCKazx58qTWrVunCRMmaNy4cfbpRTkt/nI+//xzVa1aVV988YXDtr/44ouXXTZ/mxMSEhyONhw/frzAHVirVaum9PR0tWvXzkmVy77uCxmGoQMHDlzR2QvVqlXTb7/9prZt2/7rF4Fq1arJZrNpz549l72x3IWqVKmi33//XTabzeFo98X/zwBASZObmytJSk9Pl3TlY6h0/ukdEydOVP/+/bVjxw4NGjRIO3fudDhtWzofFA8dOuTwo+3+/fslnX96SWEqVKggHx8f7du3r8C8vXv3ymq12n9wvZqAeOF4eLGL11WtWjV98803uu222wr9QbioClv3/v375ePjc9kgX61aNRmGoaioqH/9EbxatWqSpF27dl3VeJ7/3SghIcHhZnQpKSk6deoU4yGuC67pBq6Ti0+r9vPzU/Xq1R0eV5H/rMpTp045tO3SpYvy8vI0a9Ysh+lvvvmmLBaLOnfuLEnq2LGjJGn27NkO7WbOnHnFdeb/ymxc9NiTot7h+2rXtWnTJm3cuPGyy7Zr105lypTRzJkzHZYvrM6ePXtq48aN9qMXFzp16pT9C9rVWrRokc6cOWN///nnn+vo0aP2v49/07NnT/3999969913C8zLyspSRkaGJKlHjx6yWq2aOHFigbMMLv47ulCXLl2UnJysTz/91D4tNzdXM2fOlJ+fn1q1anXZGgGguDl37pzWrl0rDw8Pe8C60jH03Llz6tevnyIiIjRjxgwtWLBAKSkpGjFiRKHrurA/wzA0a9YslSlTRm3bti20vZubmzp06KCvvvrK4RT0lJQULVmyRM2bN1dAQICkS38fKEx4eLjq16+vhQsXOlwCFhcXpz179ji07dmzp/Ly8vTSSy8V6Cc3N/eK1leYjRs3OpzGnpSUpK+++kodOnS45Jlv+e6++265ublpwoQJBcY1wzDs358aNmyoqKgoTZ8+vUCdlxsPpYLfD/LPNPu3J7wAzsKRbuA6qVWrllq3bq1GjRqpXLly2rJliz7//HOHG7Hk34Rk2LBh6tixo9zc3PTAAw/ojjvuUJs2bfT888/rjz/+UL169bR27Vp99dVXGj58uP3X30aNGumee+7R9OnT9c8//9gfGZb/6/uV/HIeEBCgli1baurUqTp37pwqVqyotWvX6vDhw07/TLp166YvvvhCd911l7p27arDhw9r7ty5qlWrlv0IxaVUqFBBTz/9tCZPnqxu3bqpS5cu2r59u1atWlXgWvJRo0bp66+/Vrdu3dSvXz81atRIGRkZ2rlzpz7//HP98ccfBZa5EuXKlVPz5s3Vv39/paSkaPr06apevboeeeSRyy7bp08fLV26VI899pi+++473XbbbcrLy9PevXu1dOlSrVmzRo0bN1b16tX1/PPP66WXXlKLFi109913y9PTU5s3b1ZERIQmT55caP+DBw/WO++8o379+mnr1q264YYb9Pnnn2vDhg2aPn16gWsbAaA4WrVqlf2I9bFjx7RkyRIlJCTo2WeftQfYKx1DJ02apB07dmjdunXy9/fXTTfdpHHjxmns2LG699577eFNkry8vLR69Wr17dtXt9xyi1atWqUVK1boueee+9cju5MmTVJcXJyaN2+uJ554Qu7u7nrnnXeUnZ2tqVOn2tvVr19fbm5umjJlik6fPi1PT0/dfvvtl7wWe/LkyeratauaN2+uAQMG6MSJE5o5c6Zq167tMJ62atVKjz76qCZPnqwdO3aoQ4cOKlOmjBISEvTZZ59pxowZuvfee6/676FOnTrq2LGjwyPDpPOPvLycatWqadKkSRozZoz++OMP9ejRQ/7+/jp8+LC+/PJLDR48WE8//bSsVqvmzJmjO+64Q/Xr11f//v0VHh6uvXv3avfu3YX+sC5J9erVU9++fTVv3jydOnVKrVq10q+//qqFCxeqR48eatOmzVVvL3DVXHDHdKDYyX80yebNmwud36pVq8s+MmzSpEnGzTffbAQFBRne3t5GzZo1jZdfftnIycmxt8nNzTWGDh1qVKhQwbBYLA6PvDhz5owxYsQIIyIiwihTpowRHR1tTJs2zeExGYZhGBkZGUZsbKxRrlw5w8/Pz+jRo4exb98+Q5LDI7zyH6lx4aNN8v3111/GXXfdZQQFBRmBgYHGfffdZxw5cuSSjx27uI++ffsavr6+l/2cbDab8corrxhVqlQxPD09jQYNGhjLly83+vbt6/CIk0vJy8szJkyYYISHhxve3t5G69atjV27dhX47PM/vzFjxhjVq1c3PDw8jODgYOPWW281XnvtNYe/g4u3sTD5jwz7+OOPjTFjxhghISGGt7e30bVrV+PPP//8122+UE5OjjFlyhSjdu3ahqenp1G2bFmjUaNGxoQJE4zTp087tP3ggw+MBg0a2Nu1atXKiIuLc1jPxY92SUlJMfr3728EBwcbHh4eRt26dY358+f/67YBQHFQ2CPDvLy8jPr16xtz5swpMDZebgzdunWr4e7u7vAYMMM4Py43adLEiIiIsD+mKn+MO3jwoNGhQwfDx8fHCA0NNV588cUCj3YsbEzZtm2b0bFjR8PPz8/w8fEx2rRpY/z8888FtvHdd981qlatari5uV3R48P+3//7f0ZMTIzh6elp1KpVy/jiiy8uOZ7OmzfPaNSokeHt7W34+/sbdevWNUaPHm0cOXLE3uZqHhkWGxtrfPTRR0Z0dLR9PL+43n/73pFff/PmzQ1fX1/D19fXqFmzphEbG2vs27fPod1PP/1ktG/f3vD39zd8fX2Nm266yZg5c2aB9Vzo3LlzxoQJE4yoqCijTJkyRuXKlY0xY8YYZ8+evez2Ac5gMYx/OR8DQImwY8cONWjQQB999JF69erl6nKKve+//15t2rTRZ599VqQjAgCA4qtfv376/PPPL3tGVmlhsVgUGxtb4PR9AP+Ha7qBEiYrK6vAtOnTp8tqtaply5YuqAgAAAAovbimGyhhpk6dqq1bt6pNmzZyd3fXqlWrtGrVKg0ePJjHUAEAAADXGaEbKGFuvfVWxcXF6aWXXlJ6eroiIyM1fvx4Pf/8864uDQAAACh1uKYbAAAAAACTcE03AAAAAAAmIXQDAAAAAGASrum+AjabTUeOHJG/v78sFourywEAoEgMw9CZM2cUEREhq9V1v7szrgIASoIrHVcJ3VfgyJEj3PUZAFBiJCUlqVKlSi5bP+MqAKAkudy4Sui+Av7+/pLOf5gBAQEurgYAgKJJS0tT5cqV7eOaqzCuAgBKgisdVwndVyD/1LeAgAC+HAAAij1Xn9LNuAoAKEkuN65yIzUAAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJO6uLgAoaRITE5Wamuq0/oKDgxUZGem0/gAAAABcP4RuwIkSExNVMyZGWZmZTuvT28dHe+PjCd4AAABAMUToBpwoNTVVWZmZ6jlpjkKioq+5v2OHE7R07ONKTU0ldAMAAADFEKEbMEFIVLQqxtRzdRkAAAAAXIwbqQEAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJnF3dQEALi8+Pt5pfQUHBysyMtJp/QEAAAC4NEI38B92JjVFFqtVvXv3dlqf3j4+2hsfT/AGAAAArgNCN/AflnUmTYbNpp6T5igkKvqa+zt2OEFLxz6u1NRUQjcAAABwHRC6gWIgJCpaFWPquboMAAAAAFeJG6kBAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACZxaejOy8vTCy+8oKioKHl7e6tatWp66aWXZBiGvY1hGBo3bpzCw8Pl7e2tdu3aKSEhwaGfEydOqFevXgoICFBQUJAGDhyo9PR0hza///67WrRoIS8vL1WuXFlTp069LtsIAAAAACi9XBq6p0yZojlz5mjWrFmKj4/XlClTNHXqVM2cOdPeZurUqXrrrbc0d+5cbdq0Sb6+vurYsaPOnj1rb9OrVy/t3r1bcXFxWr58uX744QcNHjzYPj8tLU0dOnRQlSpVtHXrVk2bNk3jx4/XvHnzruv2AgAAAABKF3dXrvznn39W9+7d1bVrV0nSDTfcoI8//li//vqrpPNHuadPn66xY8eqe/fukqRFixYpNDRUy5Yt0wMPPKD4+HitXr1amzdvVuPGjSVJM2fOVJcuXfTaa68pIiJCixcvVk5Ojj744AN5eHiodu3a2rFjh9544w2HcA4AAAAAgDO59Ej3rbfeqnXr1mn//v2SpN9++00//fSTOnfuLEk6fPiwkpOT1a5dO/sygYGBuuWWW7Rx40ZJ0saNGxUUFGQP3JLUrl07Wa1Wbdq0yd6mZcuW8vDwsLfp2LGj9u3bp5MnT5q+nQAAAACA0smlR7qfffZZpaWlqWbNmnJzc1NeXp5efvll9erVS5KUnJwsSQoNDXVYLjQ01D4vOTlZISEhDvPd3d1Vrlw5hzZRUVEF+sifV7ZsWYd52dnZys7Otr9PS0u71k0FAAAAAJRCLj3SvXTpUi1evFhLlizRtm3btHDhQr322mtauHChK8vS5MmTFRgYaH9VrlzZpfUAAAAAAIonl4buUaNG6dlnn9UDDzygunXrqk+fPhoxYoQmT54sSQoLC5MkpaSkOCyXkpJinxcWFqZjx445zM/NzdWJEycc2hTWx4XruNCYMWN0+vRp+yspKckJWwsAAAAAKG1cGrozMzNltTqW4ObmJpvNJkmKiopSWFiY1q1bZ5+flpamTZs2qVmzZpKkZs2a6dSpU9q6dau9zbfffiubzaZbbrnF3uaHH37QuXPn7G3i4uJUo0aNAqeWS5Knp6cCAgIcXgAAAAAAXC2Xhu477rhDL7/8slasWKE//vhDX375pd544w3dddddkiSLxaLhw4dr0qRJ+vrrr7Vz5049/PDDioiIUI8ePSRJMTEx6tSpkx555BH9+uuv2rBhg4YMGaIHHnhAERERkqSHHnpIHh4eGjhwoHbv3q1PP/1UM2bM0MiRI1216QAAAACAUsClN1KbOXOmXnjhBT3xxBM6duyYIiIi9Oijj2rcuHH2NqNHj1ZGRoYGDx6sU6dOqXnz5lq9erW8vLzsbRYvXqwhQ4aobdu2slqtuueee/TWW2/Z5wcGBmrt2rWKjY1Vo0aNFBwcrHHjxvG4MAAAAACAqVwauv39/TV9+nRNnz79km0sFosmTpyoiRMnXrJNuXLltGTJkn9d10033aQff/yxqKUCAAAAAHDVXHp6OQAAAAAAJRmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJO4u7oAwNUSExOVmprqlL7i4+Od0g8AAACAkoHQjVItMTFRNWNilJWZ6epSAAAAAJRAhG6UaqmpqcrKzFTPSXMUEhV9zf3t27BOcbMnO6EyAAAAACUBoRuQFBIVrYox9a65n2OHE5xQDQAAAICSghupAQAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACZxd3UBAK6/+Ph4p/UVHBysyMhIp/UHAAAAlCSEbqAUOZOaIovVqt69ezutT28fH+2Njyd4AwAAAIUgdAOlSNaZNBk2m3pOmqOQqOhr7u/Y4QQtHfu4UlNTCd0AAABAIQjdQCkUEhWtijH1XF0GAAAAUOJxIzUAAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABM4vLQ/ffff6t3794qX768vL29VbduXW3ZssU+3zAMjRs3TuHh4fL29la7du2UkJDg0MeJEyfUq1cvBQQEKCgoSAMHDlR6erpDm99//10tWrSQl5eXKleurKlTp16X7QMAAAAAlF4uDd0nT57UbbfdpjJlymjVqlXas2ePXn/9dZUtW9beZurUqXrrrbc0d+5cbdq0Sb6+vurYsaPOnj1rb9OrVy/t3r1bcXFxWr58uX744QcNHjzYPj8tLU0dOnRQlSpVtHXrVk2bNk3jx4/XvHnzruv2AgAAAABKF3dXrnzKlCmqXLmy5s+fb58WFRVl/7NhGJo+fbrGjh2r7t27S5IWLVqk0NBQLVu2TA888IDi4+O1evVqbd68WY0bN5YkzZw5U126dNFrr72miIgILV68WDk5Ofrggw/k4eGh2rVra8eOHXrjjTccwjkAAAAAAM7k0iPdX3/9tRo3bqz77rtPISEhatCggd599137/MOHDys5OVnt2rWzTwsMDNQtt9yijRs3SpI2btyooKAge+CWpHbt2slqtWrTpk32Ni1btpSHh4e9TceOHbVv3z6dPHnS7M0EAAAAAJRSLg3dhw4d0pw5cxQdHa01a9bo8ccf17Bhw7Rw4UJJUnJysiQpNDTUYbnQ0FD7vOTkZIWEhDjMd3d3V7ly5RzaFNbHheu4UHZ2ttLS0hxeAAAAAABcLZeeXm6z2dS4cWO98sorkqQGDRpo165dmjt3rvr27euyuiZPnqwJEya4bP0AAAAAgJLBpUe6w8PDVatWLYdpMTExSkxMlCSFhYVJklJSUhzapKSk2OeFhYXp2LFjDvNzc3N14sQJhzaF9XHhOi40ZswYnT592v5KSkoq6iYCAAAAAEoxl4bu2267Tfv27XOYtn//flWpUkXS+ZuqhYWFad26dfb5aWlp2rRpk5o1ayZJatasmU6dOqWtW7fa23z77bey2Wy65ZZb7G1++OEHnTt3zt4mLi5ONWrUcLhTej5PT08FBAQ4vAAAAAAAuFouDd0jRozQL7/8oldeeUUHDhzQkiVLNG/ePMXGxkqSLBaLhg8frkmTJunrr7/Wzp079fDDDysiIkI9evSQdP7IeKdOnfTII4/o119/1YYNGzRkyBA98MADioiIkCQ99NBD8vDw0MCBA7V79259+umnmjFjhkaOHOmqTQcAAAAAlAIuvaa7SZMm+vLLLzVmzBhNnDhRUVFRmj59unr16mVvM3r0aGVkZGjw4ME6deqUmjdvrtWrV8vLy8veZvHixRoyZIjatm0rq9Wqe+65R2+99ZZ9fmBgoNauXavY2Fg1atRIwcHBGjduHI8LAwAAAACYyqWhW5K6deumbt26XXK+xWLRxIkTNXHixEu2KVeunJYsWfKv67npppv0448/FrlOAAAAAACulktPLwcAAAAAoCQjdAMAAAAAYBJCNwAAAAAAJinyNd0ZGRlav369EhMTlZOT4zBv2LBh11wYAAAAAADFXZFC9/bt29WlSxdlZmYqIyND5cqVU2pqqnx8fBQSEkLohqkSExOVmprqlL7i4+Od0g8AAAAAFKZIoXvEiBG64447NHfuXAUGBuqXX35RmTJl1Lt3bz355JPOrhGwS0xMVM2YGGVlZrq6FAAA4AQJCQk6c+aMq8twKn9/f0VHR7u6DAD/EUUK3Tt27NA777wjq9UqNzc3ZWdnq2rVqpo6dar69u2ru+++29l1ApKk1NRUZWVmquekOQqJuvbBbN+GdYqbPdkJlQEAgKuVkJCgG2+80bT+w/wserSRh97ZmqPkdMO09RRm//79BG8AkooYusuUKSOr9fw92EJCQpSYmKiYmBgFBgYqKSnJqQUChQmJilbFmHrX3M+xwwlOqAYAABRF/hHujz76SDExMU7v3/vUfsX88KjuH7dAWUHmhfsLxcfHq3fv3iXu6D2AoitS6G7QoIE2b96s6OhotWrVSuPGjVNqaqo+/PBD1alTx9k1AgAAoASLiYlRw4YNnd/xEav0gxRTs6YUUd/5/QPAFSjSI8NeeeUVhYeHS5JefvlllS1bVo8//riOHz+uefPmObVAAAAAAACKqyId6W7cuLH9zyEhIVq9erXTCgIAAAAAoKQo0pFuAAAAAABweVd8pLthw4Zat26dypYtqwYNGshisVyy7bZt25xSHAAAAAAAxdkVh+7u3bvL09NTktSjRw+z6gEAAAAAoMS44tD94osvFvpnAAAAAABQuCJd071582Zt2rSpwPRNmzZpy5Yt11wUAAAAAAAlQZFCd2xsrJKSkgpM//vvvxUbG3vNRQEAAAAAUBIUKXTv2bNHDRs2LDC9QYMG2rNnzzUXBQAAAABASVCk0O3p6amUlJQC048ePSp39yI9+hsAAAAAgBKnSKG7Q4cOGjNmjE6fPm2fdurUKT333HNq376904oDAAAAAKA4K1Lofu2115SUlKQqVaqoTZs2atOmjaKiopScnKzXX3/d2TUCAAD852VmZmrbtm3KzMx0dSlAscW/I5RERQrdFStW1O+//66pU6eqVq1aatSokWbMmKGdO3eqcuXKzq4RAADgP2/v3r1q1KiR9u7d6+pSgGKLf0coiYp8Abavr68GDx7szFoAAAAAAChRihy6ExIS9N133+nYsWOy2WwO88aNG3fNhQEAAAAAUNwVKXS/++67evzxxxUcHKywsDBZLBb7PIvFQugGAAAAAEBFDN2TJk3Syy+/rGeeecbZ9QAAAAAAUGIU6UZqJ0+e1H333efsWgAAAAAAKFGKFLrvu+8+rV271tm1AAAAAABQohTp9PLq1avrhRde0C+//KK6deuqTJkyDvOHDRvmlOIAAAAAACjOihS6582bJz8/P61fv17r1693mGexWAjdAAAAAACoiKH78OHDzq4DAAAAAIASp0jXdOfLycnRvn37lJub66x6AAAAAAAoMYp0pDszM1NDhw7VwoULJUn79+9X1apVNXToUFWsWFHPPvusU4sEAAD/HT/88IOmTZumrVu36ujRo/ryyy/Vo0cPl9Ry4MAB1apVS+fOnVOZMmW0Z88eRUZGavbs2Tp48KCqVaumJ554Qnl5eRo1apQSEhIUHR2tadOmycPDQz/++KOOHj2q8PBwtWjRQm5ubva+09PT1adPH3s/77//vhYtWuTQr4eHh0u2Gyip9u/fL0lq1KiR0/u++eabdejQIZ05c0Y5OTmyWq3y8vJS1apVZbPZdOjQIfv0yMhIpaeny9PTUxkZGQoKClJgYKDat2+v9u3bq3z58mrYsKEMw5DFYtEvv/yiRYsWKSEhQVWrVlWHDh301ltvadu2bXJzc5O/v7+qVasmf39/xcTEyM3NTV5eXpo3b55Onz6tSpUqadKkScrKytLx48dVoUIFVaxYscB+6cSJE2rVqpX+/PNPWSwWNW/eXLfffruGDh0qNzc3+z7NarVq4MCBysrKko+Pj7Zv367ly5c77L8kafbs2dq3b5+Sk5MVFhYmNzc3NWnSRCdPnlSFChUUFhamc+fOafHixUpPT1fz5s31xBNPaNOmTQX2nVlZWRo1apT2798vX19f9ejRQ1WqVCmwDYXJXzYhIUHVqlXTnXfeqZMnTzr0n5OTU2Dfnr8PzsvL+9f9uaR/Xd5sRQrdY8aM0W+//abvv/9enTp1sk9v166dxo8fT+gGAKAEy8jIUL169TRgwADdfffdLqvDarXKMAz7+3Pnzik6OrpAuxEjRji8X7t2rd5++235+PgoMzPTPv2GG27Q66+/rrvvvls333yzNm/ebJ+3c+dOLVu2zKGfUaNGacSIEZo6daqTtggo3SwWi6n9//rrrw7v8/LylJGRoZ07dxaYfvDgQYdp//zzjyRp27ZtmjJlisM8wzB0yy23OEybO3euw/uTJ08qMTFRkvT1118XqC0+Pl733HNPgekX7pfCwsKUkpLiMH/lypVauXKlRo0aJX9/f6WlpRXoIz09vcC+ceTIkfbar8ayZcv09NNPF6ixQoUKDvvM/LYXb0NhevTooa+++sph2pw5cxz6r1evnlasWOFwhnX+Prhp06Z66qmn9Mcffzgsc+E6R48erTfffLPQ5a/HPrxIp5cvW7ZMs2bNUvPmzR3+cdSuXbvA/6AAAKBk6dy5syZNmqS77rrLZTVcGLh9fHw0bdo0ubs7Hks4evSo6tevb39/yy236MCBA/a6MzMz1aJFC505c0YbN25U3bp1de+996p69eravHmzLBaL+vTpo759+zr0W69ePb377rsqX768pk2bptGjR5u7sUApYHbgNktYWJhT+rlw+wMCAtS5c2dZLBYFBwfr3nvvVVBQkEPg9vPz0w033GB/bxhGgcB98ROmJMnNzU0dO3aUYRj2fai/v799nnR+/3rxMpIKhOYnn3xSGzdu1NmzZ7V582b7crfffrv69OljX//Zs2d177336osvvihQT37g9vDwsO+bq1evbl82/4j1V199JV9fX7377rs6evSowz74nnvuUd26dbVx48YC+/MvvvhCo0eP1rRp01S+fPlCl78e+/Aihe7jx48rJCSkwPSMjIxi+w8GAAAUDwcOHLB/WTx69KgyMjLsT04JDg62tzt+/Lh27NghDw8PhYSEaOvWrYqIiND27dvVtWtX++nlbm5uatq0qZYtW6ZOnTrp4MGDslgsyszM1HvvvafFixcrNDRUZ86ckcVi0W+//aYHHnhAf/31l0JDQ/Xmm28qJyfHJZ8FUBLs27fP1SUUibe3t5KTk+Xh4aG9e/c6zLswE0VERBQIsvk8PDzk5uYmq9Wq8uXLS5LS0tK0aNEidevWTf/884/at2+v06dP25cJDQ3VyZMndfjwYZ06darQfo8fP660tDRZLBa5ubnpr7/+knT+KP7atWtVoUIFe9ugoCB169ZNERER9tOt8+v38PBQ5cqV1bVrV3399dfq2rWrunTpIjc3N7399tuKiYlRcnKyLBaLrFarunXrpri4OC1atEjp6eny8PBQcnKyOnfurKefflp5eXn29WZlZdkD96lTp7R9+3bdcccd2rdvn33ZH3/8UYcPH5aHh4fKli2r/v37KywsTIMGDdKff/4pq9Uqi8WipUuXqmnTpvLz87Pvz7t166annnpKb7zxhkJDQ/XXX39p0KBB9uWv5z68SKeXN27cWCtWrNDQoUMl/d9fynvvvadmzZo5rzoAAFDsZWdnKzs72/6+sNMfr0atWrUknT/CnX+Uafbs2crNzdXkyZP15JNPKjMzU/Xq1ZN0/jTKqKgoPfrooxo1apT++OMPffzxx6pdu7amTp2qUaNGadasWbJarcrIyJB0/pI5Ly8vTZ8+Xbm5uZo0aZL8/Pz00EMPafHixerTp4++/PJLTZw4UY8++qhmz56tJk2aSDp/miiuTP5nlZWV5eJKnCd/W/j/4MrdfPPNri7hX5UpU0bnzp0rMD3/7/ree+/V0aNHHeZFR0fbr08/cuRIgWU9PT2VnZ3tEPb69eun119/XZLUpk0bzZs3T7feeqvOnj3rsOykSZPsZ/Zs3769QN8+Pj4KDg7W9OnTZRiG8vLylJCQoHLlyunEiRMyDENt2rTR0qVLJUlJSUl69tlntXz5cj3zzDMOp8+3aNFC69at05133qnc3Fx16dJFDRo00MqVKyVJXbt2lXR+nxkXF6fOnTvbf2Dw8PDQ8OHDNXXqVHl7e+vw4cP68ccf1bp1a0nnT++Wzu+jN23aZN83W61Wh2VtNptGjhypV1991WH5jRs3ymazSTp/Ov/w4cPtdVutVo0ZM0a33nprgc8sn7u7u8M+/MLlna1IofuVV15R586dtWfPHuXm5mrGjBnas2ePfv755wLP7QYAAKXb5MmTNWHCBKf1l//l98I+8y9v69atm1JSUjR27Fj70fBBgwbJ29tbkpSQkCBJqlOnjsqVK6epU6fap0lSamqqJKlt27YF+pXOfzlcvHhxgekHDx60Hznq3bu307a1tPjjjz902223uboMp8i/rpT/D0qOy1333Lhx4wKhu1y5cv+6THBwsP7++2+HaVWrVrX/+ciRI6pTp46kgj9U5u93JBVYryT7D4AXXvZ79OhRTZw4UUOGDJEk+fr6OiyTv48cOHCgQ+gODw+XJHvw9/b2ttclyX6d+u233664uDh7P/kGDhyoqVOn6uTJkwXqzd/3Dho0yH69/YV95y+b/+dXX33VYfkL/1zYJc4X9nXhZ3ahC/fhZipS6G7evLl27NihV199VXXr1tXatWvVsGFD+/nzAAAA+caMGWO/aY90/gtk5cqVi9xf/lGnF1980X5Dn2rVqkmSli9frldeeUXS+TPxDMPQe++9p6ioKEnnjz6tXbtWu3bt0pdffmmfli//9PR169bpmWeeceh30KBBeuONNwqsL/99/vWVH330kWJiYoq8faVJfHy8evfu7XBtanHH/wdX7+abb3Y47fi/5nKXz27ZskWPPPKIw7QTJ0786zL5P/Bd6NChQ/Y/R0REaNeuXZLOX+OdfxaO9H/7I+n/QvGF8m9olr+fym+XH7glOfQn/d9R+/fff99hen6w9fLysrfLr0uSIiMjlZSUpG+//dahn3z5/ZUtW7ZAvfn74/fee08dO3aUJO3atUtNmzYtUEv+ny9c/sI/X7it+S6s88LP7EIX7sPNZDGu9pZ1pVBaWpoCAwN1+vRpBQQEuLqcUm3btm1q1KiRhiz+RhVj6l1zf9tXfq6lYx+nvyL6O/43zerVTlu3blXDhg2vuT8A5jJjPLNYLFf9yLBrrePAgQP2oHz06FGFhYUpJydHvr6+CgoKsn+Z/f3333XTTTfJw8NDQUFBOnHihNLS0lSrVi3Vrl1bcXFxysnJUWZmpry9vWWz2dStWzetWrXKfk231WqVr6+vypcvrwMHDiggIECGYejMmTPy8vJSpUqV9M8//ygjI0O7du1So0aN2Cdehfxx3bTP7MgOaV4rafB6KaK+8/svhOnbVALt27dPNWvWdHUZV83b21tZWVny8PDQ77//7rAN+T/6SecDdHJysv1U6At5eHjYf3AICgqy3yX9+PHjGjBggHbt2mUPp/nyr092d3fX6dOnFRQUVKDf48ePy8/PTz4+PrJarfrzzz9VqVIle23BwcE6fvy4JKly5cqqV6+efvvtN6WkpCg3N9d+ozUPDw9FRESodu3aWrNmjf0mbGvWrJHFYlFqaqqCgoLs14536tRJX331laxWq3JycuTv76+cnBx16dJF8fHxSkhIsN+YLf9xZvnXdNeqVUt169bVsmXLlJuba1/WarXK3d1dEREROnDggH357Oxs+fj4yDAMZWZm2n8YkCSbzaYePXpo586dSkpKUnBwsP0zy5ebm+uwDy/K48OudDwr0o3UEhMT//UFAABKrvT0dO3YsUM7duyQJB0+fFg7duy4bt8Bqlevbj/yFB4eLl9fX02bNk2S49Gj8uXL66abblJOTo6OHTumBg0aKCkpyf7omZycHLVo0UK5ubnauHGjevToodWrV6tatWoyDEM+Pj4aMGCAHnroIaWkpMjf31+GYahevXpasmSJKlWqpJSUFI0YMYLndQPXoEaNGq4uoUiysrIUEhKinJycAj8aXHhc88iRI4UGbun8s6Pz8vJks9nsgTsgIEAPP/ywli9frvLlyysuLk6BgYH2ZVJSUlS2bFlVqVKl0MAtSRUqVLDvs/Ly8uyB283NTe3bt7cHbkk6deqUli9friNHjtivMc+vPycnR0lJSVqxYoXuuOMOrVixQitXrlReXp5iY2O1Z88ehYWFyTAM2Ww2LV++XO3atVPv3r3l5+ennJwchYWFadWqVXrttdccnp3t7e2t7t27KycnR0FBQapXr57+97//6cYbb7Qv26JFC0VFRSknJ0cnT57U+++/ryNHjmjevHmqUqWKbDabDMNQz549He5e3qNHDy1fvlyvv/66Ro4cqZSUFFWqVEnz5s2zL3899+FFOr38hhtu+NfTLP7Lp4cAAIBrs2XLFrVp08b+Pv/U8b59+2rBggXXpQabzWZ/bFhmZqbGjh1boE3FihUd3m/evNnhy72Pj49+/PFH+9GJqKgoff755w7P6V68eHGBfn/77Tc9+uijcnd316hRo3hON+AEhmEUy6cgHTt2zCn9XBjS09LStGrVKknnnw+ev1+68Dnd6enpSk9Pty9jsVgKPKf7wmdS58u/e3n+Z51/5k7+PEkFfiDIn55/SU6+GTNmaMaMGYqKilKTJk3sp7V/9913Du28vb3t23CxZcuW2R8blv+s7guvr/7xxx8VFRWl7t27a8WKFXr00Uft8/L3wfnP6c6/aZrkuD/PX++bb75Z6PLXYx9epNB98V3yzp07p+3bt+uNN97Qyy+/7JTCAADAf1Pr1q0ve2Oh68Fms+nAgQOqVauWzp07pzJlymjPnj2KjIzU7NmzdfDgQVWrVk1PPPGE8vLyNGrUKCUkJCg6OlrTpk2zP47m6NGjCg8Ptz8PVpJ+/fVXpaenq0+fPvZ+3n//fS1atMihX45wA85jGIY++eQTPfjgg6b0f/PNN+vQoUM6c+aM/bRlLy8vVa1aVTabTYcOHbJPj4yMVHp6ujw9PZWRkaGgoCAFBgaqffv2at++vcqXL6+GDRvafyz45ZdftGjRIiUkJKhq1arq0KGD3nrrLW3btk1ubm7y9/dXtWrV5O/vr5iYGLm5ucnLy0vz5s3T6dOnValSJU2aNElZWVk6fvy4KlSooIoVKzrsl5KTk3XixAm1atVKf/75pywWi5o3b67bb79dQ4cOlZubm32fZrVaNXDgQPsp3Nu3b9fy5csd9l/S+Sc/7Nu3T8nJyQoLC5Obm5uaNGmikydPqkKFCgoLC9O5c+e0ePFipaenq3nz5nriiSe0adOmAvvOrKwsjRo1Svv375evr6969OihKlWqOGxDYZYtW2ZfNiEhQdWqVdOdd96pkydPOvSfk5NTYN+evw/u3r37JffnkjR16lRNmjTpksubrUihO/8RHBdq3LixIiIiNG3atEJ/xQAAAHC26tWrF/p81cIe/TJr1qwC0/IfPVMYPz+/Akd2zHykDADpxhtvlKRicU38xUeEL3702V133XXZPl544YWrWme5cuW0c+fOS86/cJ92//33O8wrbP91pfu0Tp06XXI9+by9vQvdz16JK1k2/zFihXFzc/vX/fnlljdbka7pvpQaNWrYTysAAAAAAKC0K9KR7oufFWcYho4eParx48c7PHYDAAAAAIDSrEihO/+28BcyDEOVK1fWJ5984pTCAAAAAAAo7ooUur/99luH0G21WlWhQgVVr17d4dlnAAAAAACUZkVKyJe7SB0AAAAAABTxRmqTJ0/WBx98UGD6Bx98oClTplxzUQAAAAAAlARFCt3vvPOOatasWWB67dq1NXfu3GsuCgAAAACAkqBIoTs5OVnh4eEFpleoUEFHjx695qIAAAAAACgJihS6K1eurA0bNhSYvmHDBkVERFxzUQAAAAAAlARFupHaI488ouHDh+vcuXO6/fbbJUnr1q3T6NGj9dRTTzm1QAAAgOKgZs2a2rp1a6GX4AG4Mvw7QklUpNA9atQo/fPPP3riiSeUk5MjSfLy8tIzzzyjMWPGOLVAAACA4sDHx0cNGzZ0dRlAsca/I5RERQrdFotFU6ZM0QsvvKD4+Hh5e3srOjpanp6ezq4PAAAAAIBiq0jXdOdLTk7WiRMnVK1aNXl6esowDGfVBQAAAABAsVek0P3PP/+obdu2uvHGG9WlSxf7HcsHDhzINd0AAAAAAPz/ihS6R4wYoTJlyigxMVE+Pj726ffff79Wr17ttOIAAAAAACjOinRN99q1a7VmzRpVqlTJYXp0dLT+/PNPpxQGAAAAAEBxV6Qj3RkZGQ5HuPOdOHGCm6kBAAAAAPD/K1LobtGihRYtWmR/b7FYZLPZNHXqVLVp08ZpxQEAAAAAUJwV6fTyqVOnqm3bttqyZYtycnI0evRo7d69WydOnNCGDRucXSMAAAAAAMVSkY5016lTR/v371fz5s3VvXt3ZWRk6O6779b27dtVrVo1Z9cIAAAAAECxdNVHus+dO6dOnTpp7ty5ev75582oCQAAAACAEuGqj3SXKVNGv//+uxm1AAAAAABQohTpmu7evXvr/fff16uvvursegAAAFBKZGZmSpK2bdtmSv/ep/YrRlL83r3KSraZso6LxcfHX5f1ACg+ihS6c3Nz9cEHH+ibb75Ro0aN5Ovr6zD/jTfecEpxAAAAKLn27t0rSXrkkUdM6T/Mz6JHG3nondcfUnK6Yco6LsXf3/+6rg/Af9dVhe5Dhw7phhtu0K5du9SwYUNJ0v79+x3aWCwW51UHAACAEqtHjx6SpJo1a8rHx8e09dxpWs+F8/f3V3R09HVeK4D/qqsK3dHR0Tp69Ki+++47SdL999+vt956S6GhoaYUB6B4cNapdMHBwYqMjHRKXwCA/77g4GANGjTI1WUAgKmuKnQbhuNpOatWrVJGRoZTCwJQfJxJTZHFalXv3r2d0p+3j4/2xscTvAEAAFBiFOma7nwXh/Br8eqrr2rMmDF68sknNX36dEnS2bNn9dRTT+mTTz5Rdna2OnbsqNmzZzscWU9MTNTjjz+u7777Tn5+furbt68mT54sd/f/27Tvv/9eI0eO1O7du1W5cmWNHTtW/fr1c1rtQGmVdSZNhs2mnpPmKCTq2k6jO3Y4QUvHPq7U1FRCNwAAAEqMqwrdFoulwDXbzriGe/PmzXrnnXd00003OUwfMWKEVqxYoc8++0yBgYEaMmSI7r77bm3YsEGSlJeXp65duyosLEw///yzjh49qocfflhlypTRK6+8Ikk6fPiwunbtqscee0yLFy/WunXrNGjQIIWHh6tjx47XXDsAKSQqWhVj6rm6DAAAAOA/56pPL+/Xr588PT0lnT8S/dhjjxW4e/kXX3xxxX2mp6erV69eevfddzVp0iT79NOnT+v999/XkiVLdPvtt0uS5s+fr5iYGP3yyy9q2rSp1q5dqz179uibb75RaGio6tevr5deeknPPPOMxo8fLw8PD82dO1dRUVF6/fXXJUkxMTH66aef9OabbxK6AQAAAACmsl5N4759+yokJESBgYEKDAxU7969FRERYX+f/7oasbGx6tq1q9q1a+cwfevWrTp37pzD9Jo1ayoyMlIbN26UJG3cuFF169Z1ON28Y8eOSktL0+7du+1tLu67Y8eO9j4Kk52drbS0NIcXAAAAAABX66qOdM+fP9+pK//kk0+0bds2bd68ucC85ORkeXh4KCgoyGF6aGiokpOT7W0uvnN6/vvLtUlLS1NWVpa8vb0LrHvy5MmaMGFCkbcLAAAAAADpKo90O1NSUpKefPJJLV68WF5eXq4qo1BjxozR6dOn7a+kpCRXlwQAAAAAKIZcFrq3bt2qY8eOqWHDhnJ3d5e7u7vWr1+vt956S+7u7goNDVVOTo5OnTrlsFxKSorCwsIkSWFhYUpJSSkwP3/ev7UJCAgo9Ci3JHl6eiogIMDhBQAAAADA1XJZ6G7btq127typHTt22F+NGzdWr1697H8uU6aM1q1bZ19m3759SkxMVLNmzSRJzZo1086dO3Xs2DF7m7i4OAUEBKhWrVr2Nhf2kd8mvw8AAAAAAMxyTc/pvhb+/v6qU6eOwzRfX1+VL1/ePn3gwIEaOXKkypUrp4CAAA0dOlTNmjVT06ZNJUkdOnRQrVq11KdPH02dOlXJyckaO3asYmNj7XdYf+yxxzRr1iyNHj1aAwYM0LfffqulS5dqxYoV13eDAQAAAACljstC95V48803ZbVadc899yg7O1sdO3bU7Nmz7fPd3Ny0fPlyPf7442rWrJl8fX3Vt29fTZw40d4mKipKK1as0IgRIzRjxgxVqlRJ7733Ho8LAwAAAACY7j8Vur///nuH915eXnr77bf19ttvX3KZKlWqaOXKlf/ab+vWrbV9+3ZnlAgAAAAAwBVz2TXdAAAAAACUdIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCQuDd2TJ09WkyZN5O/vr5CQEPXo0UP79u1zaHP27FnFxsaqfPny8vPz0z333KOUlBSHNomJieratat8fHwUEhKiUaNGKTc316HN999/r4YNG8rT01PVq1fXggULzN48AAAAAEAp59LQvX79esXGxuqXX35RXFyczp07pw4dOigjI8PeZsSIEfrf//6nzz77TOvXr9eRI0d099132+fn5eWpa9euysnJ0c8//6yFCxdqwYIFGjdunL3N4cOH1bVrV7Vp00Y7duzQ8OHDNWjQIK1Zs+a6bi8AAAAAoHRxd+XKV69e7fB+wYIFCgkJ0datW9WyZUudPn1a77//vpYsWaLbb79dkjR//nzFxMTol19+UdOmTbV27Vrt2bNH33zzjUJDQ1W/fn299NJLeuaZZzR+/Hh5eHho7ty5ioqK0uuvvy5JiomJ0U8//aQ333xTHTt2vO7bDQAAAAAoHf5T13SfPn1aklSuXDlJ0tatW3Xu3Dm1a9fO3qZmzZqKjIzUxo0bJUkbN25U3bp1FRoaam/TsWNHpaWlaffu3fY2F/aR3ya/j4tlZ2crLS3N4QUAAAAAwNX6z4Rum82m4cOH67bbblOdOnUkScnJyfLw8FBQUJBD29DQUCUnJ9vbXBi48+fnz/u3NmlpacrKyipQy+TJkxUYGGh/Va5c2SnbCAAAAAAoXf4zoTs2Nla7du3SJ5984upSNGbMGJ0+fdr+SkpKcnVJAAAAAIBiyKXXdOcbMmSIli9frh9++EGVKlWyTw8LC1NOTo5OnTrlcLQ7JSVFYWFh9ja//vqrQ3/5dze/sM3FdzxPSUlRQECAvL29C9Tj6ekpT09Pp2wbAAAAAKD0cumRbsMwNGTIEH355Zf69ttvFRUV5TC/UaNGKlOmjNatW2eftm/fPiUmJqpZs2aSpGbNmmnnzp06duyYvU1cXJwCAgJUq1Yte5sL+8hvk98HAAAAAABmcOmR7tjYWC1ZskRfffWV/P397ddgBwYGytvbW4GBgRo4cKBGjhypcuXKKSAgQEOHDlWzZs3UtGlTSVKHDh1Uq1Yt9enTR1OnTlVycrLGjh2r2NhY+9Hqxx57TLNmzdLo0aM1YMAAffvtt1q6dKlWrFjhsm0HAAAAAJR8Lj3SPWfOHJ0+fVqtW7dWeHi4/fXpp5/a27z55pvq1q2b7rnnHrVs2VJhYWH64osv7PPd3Ny0fPlyubm5qVmzZurdu7cefvhhTZw40d4mKipKK1asUFxcnOrVq6fXX39d7733Ho8LAwAAAACYyqVHug3DuGwbLy8vvf3223r77bcv2aZKlSpauXLlv/bTunVrbd++/aprBAAAAACgqP4zdy8HAAAAAKCkIXQDAAAAAGASQjcAAAAAACYhdAMAAAAAYBJCNwAAAAAAJiF0AwAAAABgEkI3AAAAAAAmIXQDAAAAAGASQjcAAAAAACZxd3UBKB0SExOVmpp6zf3Ex8c7oRoAAAAAuD4I3TBdYmKiasbEKCsz09WlAAAAAMB1ReiG6VJTU5WVmamek+YoJCr6mvrat2Gd4mZPdlJlAAAAAGAuQjeum5CoaFWMqXdNfRw7nOCkavBf5cxLCIKDgxUZGem0/gAAAICrRegG8J9wJjVFFqtVvXv3dlqf3j4+2hsfT/AGAACAyxC6AfwnZJ1Jk2GzOeUyBOn8WRFLxz6u1NRUQjcAAABchtAN4D/FGZchAAAAAP8VPKcbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJMQugEAAAAAMAmhGwAAAAAAkxC6AQAAAAAwCaEbAAAAAACTELoBAAAAADAJoRsAAAAAAJO4u7oAADBTfHy80/oKDg5WZGSk0/oDAABAyUfoBlAinUlNkcVqVe/evZ3Wp7ePj/bGxxO8AQAAcMUI3QBKpKwzaTJsNvWcNEchUdHX3N+xwwlaOvZxpaamEroBAABwxQjdAEq0kKhoVYyp5+oyAAAAUEpxIzUAAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATOLu6gIAoDiJj493Wl/BwcGKjIx0Wn8AAAD47yF0A8AVOJOaIovVqt69ezutT28fH+2Njyd4AwAAlGCEbhQqMTFRqampTunLmUcGAVfJOpMmw2ZTz0lzFBIVfc39HTucoKVjH1dqaiqhGwAAoAQjdKOAxMRE1YyJUVZmpqtLAf5zQqKiVTGmnqvLAAAAQDFB6EYBqampysrMdNoRvX0b1ilu9mQnVAYAAAAAxQuhG5fkrCN6xw4nOKEaAAAAACh+eGQYAAAAAAAm4Ug3ALgQjyADAAAo2UpV6H777bc1bdo0JScnq169epo5c6ZuvvlmV5cFoBTiEWQAAAClQ6kJ3Z9++qlGjhypuXPn6pZbbtH06dPVsWNH7du3TyEhIa4uD0ApwyPIAAAASodSE7rfeOMNPfLII+rfv78kae7cuVqxYoU++OADPfvssy6uDkBp5exHkDnrdHVOVQcAAHCOUhG6c3JytHXrVo0ZM8Y+zWq1ql27dtq4caNLakpMTFRqaqrT+svOzpanp6dT+nLmNaYArg9nn67u6eWl//f55woPD3dKf87cR5nRHz8yAAAAs5SK0J2amqq8vDyFhoY6TA8NDdXevXsLtM/OzlZ2drb9/enTpyVJaWlpTqknKSlJjZs00dmsLKf0J0myWCTDcF5/kv6O/105mRnX3M/xPxKc1p8z+6K//1Z//+XaikN/iTu3yrDZ1OLhWAWFVbymvpIP7tXmLz5Ut27drrkuO2fvo5zcn6eXlz5ctKjAOFFUVqtVNpvNKX1JUlhYmMLCwq65n/xxzHDyeHG18tfvrHEVAABXuNJx1WK4euS9Do4cOaKKFSvq559/VrNmzezTR48erfXr12vTpk0O7cePH68JEyZc7zIBALgukpKSVKlSJZet/6+//lLlypVdtn4AAJzpcuNqqTjSHRwcLDc3N6WkpDhMT0lJKfTIwZgxYzRy5Ej7e5vNphMnTqh8+fI6c+aMKleurKSkJAUEBJheuyukpaWV+G2USsd2so0lR2nYztKwjZJrt9MwDJ05c0YRERHXdb0Xi4iIUFJSkgzDUGRkJH/nJUBp2EapdGwn21hylIbtdPU2Xum4WipCt4eHhxo1aqR169apR48eks4H6XXr1mnIkCEF2nt6eha4VjAoKEiSZLFYJEkBAQEl9n/efKVhG6XSsZ1sY8lRGrazNGyj5LrtDAwMvO7rvJjValWlSpXsp+Xxd15ylIZtlErHdrKNJUdp2E5XbuOVjKulInRL0siRI9W3b181btxYN998s6ZPn66MjAz73cwBAAAAAHC2UhO677//fh0/flzjxo1TcnKy6tevr9WrVzvtpjkAAAAAAFys1IRuSRoyZEihp5NfDU9PT7344otOfVTNf01p2EapdGwn21hylIbtLA3bKJWe7bwSpeWzKA3bWRq2USod28k2lhylYTuLyzaWiruXAwAAAADgClZXFwAAAAAAQElF6AYAAAAAwCSEbgAAAAAATELovgKTJ09WkyZN5O/vr5CQEPXo0UP79u1zdVlON2fOHN10003259w1a9ZMq1atcnVZpnr11VdlsVg0fPhwV5fiVOPHj5fFYnF41axZ09VlOd3ff/+t3r17q3z58vL29lbdunW1ZcsWV5flVDfccEOBv0uLxaLY2FhXl+Y0eXl5euGFFxQVFSVvb29Vq1ZNL730kkraLUfOnDmj4cOHq0qVKvL29tatt96qzZs3u7osl2BcLblK4rhaWsZUqeSPq4ypJUtxGldL1d3Li2r9+vWKjY1VkyZNlJubq+eee04dOnTQnj175Ovr6+rynKZSpUp69dVXFR0dLcMwtHDhQnXv3l3bt29X7dq1XV2e023evFnvvPOObrrpJleXYoratWvrm2++sb93dy9Z/9xPnjyp2267TW3atNGqVatUoUIFJSQkqGzZsq4uzak2b96svLw8+/tdu3apffv2uu+++1xYlXNNmTJFc+bM0cKFC1W7dm1t2bJF/fv3V2BgoIYNG+bq8pxm0KBB2rVrlz788ENFREToo48+Urt27bRnzx5VrFjR1eVdV4yrjKvFTUkfU6XSMa4yppacMVUqZuOqgat27NgxQ5Kxfv16V5diurJlyxrvvfeeq8twujNnzhjR0dFGXFyc0apVK+PJJ590dUlO9eKLLxr16tVzdRmmeuaZZ4zmzZu7uozr7sknnzSqVatm2Gw2V5fiNF27djUGDBjgMO3uu+82evXq5aKKnC8zM9Nwc3Mzli9f7jC9YcOGxvPPP++iqv47GFeLv5I8rpaGMdUwSue4yphafBW3cZXTy4vg9OnTkqRy5cq5uBLz5OXl6ZNPPlFGRoaaNWvm6nKcLjY2Vl27dlW7du1cXYppEhISFBERoapVq6pXr15KTEx0dUlO9fXXX6tx48a67777FBISogYNGujdd991dVmmysnJ0UcffaQBAwbIYrG4uhynufXWW7Vu3Trt379fkvTbb7/pp59+UufOnV1cmfPk5uYqLy9PXl5eDtO9vb31008/uaiq/w7G1eKvpI+rJX1MlUrfuMqYWrwVu3HV1am/uMnLyzO6du1q3Hbbba4uxRS///674evra7i5uRmBgYHGihUrXF2S03388cdGnTp1jKysLMMwjBL3i7xhGMbKlSuNpUuXGr/99puxevVqo1mzZkZkZKSRlpbm6tKcxtPT0/D09DTGjBljbNu2zXjnnXcMLy8vY8GCBa4uzTSffvqp4ebmZvz999+uLsWp8vLyjGeeecawWCyGu7u7YbFYjFdeecXVZTlds2bNjFatWhl///23kZuba3z44YeG1Wo1brzxRleX5lKMq8VfSR9XS8OYahilb1xlTC3+itO4Sui+So899phRpUoVIykpydWlmCI7O9tISEgwtmzZYjz77LNGcHCwsXv3bleX5TSJiYlGSEiI8dtvv9mnlbQvB4U5efKkERAQUKJOaSxTpozRrFkzh2lDhw41mjZt6qKKzNehQwejW7duri7D6T7++GOjUqVKxscff2z8/vvvxqJFi4xy5cqVuC96Bw4cMFq2bGlIMtzc3IwmTZoYvXr1MmrWrOnq0lyKcbV4K43jakkcUw2j9I2rjKnFX3EaVwndVyE2NtaoVKmScejQIVeXct20bdvWGDx4sKvLcJovv/zS/g8z/yXJsFgshpubm5Gbm+vqEk3TuHFj49lnn3V1GU4TGRlpDBw40GHa7NmzjYiICBdVZK4//vjDsFqtxrJly1xditNVqlTJmDVrlsO0l156yahRo4aLKjJXenq6ceTIEcMwDKNnz55Gly5dXFyR6zCuFn+ldVwtaWOqYZSucZUxtWQpDuMq13RfAcMwNGTIEH355Zf69ttvFRUV5eqSrhubzabs7GxXl+E0bdu21c6dO7Vjxw77q3HjxurVq5d27NghNzc3V5doivT0dB08eFDh4eGuLsVpbrvttgKPGNq/f7+qVKnioorMNX/+fIWEhKhr166uLsXpMjMzZbU6Dkdubm6y2Wwuqshcvr6+Cg8P18mTJ7VmzRp1797d1SVdd4yrjKvFWUkcU6XSNa4yppYsxWFcLXnPOzBBbGyslixZoq+++kr+/v5KTk6WJAUGBsrb29vF1TnPmDFj1LlzZ0VGRurMmTNasmSJvv/+e61Zs8bVpTmNv7+/6tSp4zDN19dX5cuXLzC9OHv66ad1xx13qEqVKjpy5IhefPFFubm56cEHH3R1aU4zYsQI3XrrrXrllVfUs2dP/frrr5o3b57mzZvn6tKczmazaf78+erbt2+JfEzNHXfcoZdfflmRkZGqXbu2tm/frjfeeEMDBgxwdWlOtWbNGhmGoRo1aujAgQMaNWqUatasqf79+7u6tOuOcZVxtTgpDWOqVHrGVcbUkqNYjauuPdBePEgq9DV//nxXl+ZUAwYMMKpUqWJ4eHgYFSpUMNq2bWusXbvW1WWZriRee3b//fcb4eHhhoeHh1GxYkXj/vvvNw4cOODqspzuf//7n1GnTh3D09PTqFmzpjFv3jxXl2SKNWvWGJKMffv2uboUU6SlpRlPPvmkERkZaXh5eRlVq1Y1nn/+eSM7O9vVpTnVp59+alStWtXw8PAwwsLCjNjYWOPUqVOuLsslGFdLtpI2rpaWMdUwSse4yphachSncdViGIbhirAPAAAAAEBJxzXdAAAAAACYhNANAAAAAIBJCN0AAAAAAJiE0A0AAAAAgEkI3QAAAAAAmITQDQAAAACASQjdAAAAAACYhNANAAAAAIBJCN0Aih2LxaJly5a5ugwAAIo9xlTAfIRuANekX79+slgsslgs8vDwUPXq1TVx4kTl5uaats6jR4+qc+fOpvUPAIArMKYCJZO7qwsAUPx16tRJ8+fPV3Z2tlauXKnY2FiVKVNGY8aMcWiXk5MjDw+Pa15fWFjYNfcBAMB/EWMqUPJwpBvANfP09FRYWJiqVKmixx9/XO3atdPXX3+tfv36qUePHnr55ZcVERGhGjVqSJKSkpLUs2dPBQUFqVy5curevbv++OMPhz4/+OAD1a5dW56engoPD9eQIUPs8y4+FW7nzp26/fbb5e3trfLly2vw4MFKT0+/HpsOAIBTMaYCJQ+hG4DTeXt7KycnR5K0bt067du3T3FxcVq+fLnOnTunjh07yt/fXz/++KM2bNggPz8/derUyb7MnDlzFBsbq8GDB2vnzp36+uuvVb169ULXlZGRoY4dO6ps2bLavHmzPvvsM33zzTcOXygAACiuGFOB4o/TywE4jWEYWrdundasWaOhQ4fq+PHj8vX11XvvvWc/Be6jjz6SzWbTe++9J4vFIkmaP3++goKC9P3336tDhw6aNGmSnnrqKT355JP2vps0aVLoOpcsWaKzZ89q0aJF8vX1lSTNmjVLd9xxh6ZMmaLQ0FCTtxoAAOdjTAVKDo50A7hmy5cvl5+fn7y8vNS5c2fdf//9Gj9+vCSpbt26Dtec/fbbbzpw4ID8/f3l5+cnPz8/lStXTmfPntXBgwd17NgxHTlyRG3btr2idcfHx6tevXr2LweSdNttt8lms2nfvn1O3U4AAMzGmAqUPBzpBnDN2rRpozlz5sjDw0MRERFyd/+/XcuFA7ckpaenq1GjRlq8eHGBfipUqCCrld8CAQClF2MqUPIQugFcM19f30teH3axhg0b6tNPP1VISIgCAgIKbXPDDTdo3bp1atOmzWX7i4mJ0YIFC5SRkWH/MrJhwwZZrVb7TWYAACguGFOBkoefvwBcV7169VJwcLC6d++uH3/8UYcPH9b333+vYcOG6a+//pIkjR8/Xq+//rreeustJSQkaNu2bZo5c+Yl+/Py8lLfvn21a9cufffddxo6dKj69OnDtWcAgBKNMRUoHgjdAK4rHx8f/fDDD4qMjNTdd9+tmJgYDRw4UGfPnrX/St+3b19Nnz5ds2fPVu3atdWtWzclJCRcsr81a9boxIkTatKkie699161bdtWs2bNup6bBQDAdceYChQPFsMwDFcXAQAAAABAScSRbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCSEbgAAAAAATELoBgAAAADAJIRuAAAAAABMQugGAAAAAMAkhG4AAAAAAExC6AYAAAAAwCT/H9BY/TTMIcO5AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Grid para dos plots\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Histograma de distribucion de frecuencia de precios despues de eliminar datos atipicos\n",
    "ax[0].hist(df['LOG_PRICE'], bins=20, color='skyblue', edgecolor='black')\n",
    "ax[0].set_title('Histograma del precio')\n",
    "ax[0].set_xlabel('Precio')\n",
    "ax[0].set_ylabel('Frecuencia')\n",
    "\n",
    "# Boxplot de distribucion de precios\n",
    "ax[1].boxplot(df['LOG_PRICE'], vert=False)\n",
    "ax[1].set_title('Boxplot del precio')\n",
    "ax[1].set_xlabel('Precio')\n",
    "# Mostrar la figura\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "      <th>nulls</th>\n",
       "      <th>percent_nulls</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>total_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood</th>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latitude</th>\n",
       "      <td>18616</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>14265</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_365</th>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOG_PRICE</th>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                nunique  nulls  percent_nulls    Dtype  \\\n",
       "neighbourhood_group                   5      0           0.00   object   \n",
       "neighbourhood                       218      0           0.00   object   \n",
       "latitude                          18616      0           0.00  float64   \n",
       "longitude                         14265      0           0.00  float64   \n",
       "room_type                             3      0           0.00   object   \n",
       "minimum_nights                       97      0           0.00    int64   \n",
       "number_of_reviews                   363      0           0.00    int64   \n",
       "calculated_host_listings_count       47      0           0.00    int64   \n",
       "availability_365                    366      0           0.00    int64   \n",
       "LOG_PRICE                           628      0           0.00  float64   \n",
       "\n",
       "                                non_null  total_values  \n",
       "neighbourhood_group                46724         46724  \n",
       "neighbourhood                      46724         46724  \n",
       "latitude                           46724         46724  \n",
       "longitude                          46724         46724  \n",
       "room_type                          46724         46724  \n",
       "minimum_nights                     46724         46724  \n",
       "number_of_reviews                  46724         46724  \n",
       "calculated_host_listings_count     46724         46724  \n",
       "availability_365                   46724         46724  \n",
       "LOG_PRICE                          46724         46724  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dtype\n",
       "int64      4\n",
       "object     3\n",
       "float64    3\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe tiene 46724 filas y 10 columnas\n",
      "Hay 0 valores duplicados\n"
     ]
    }
   ],
   "source": [
    "# Vuelvo a llamar a la funcion de info para ver como va quedando el df\n",
    "df_info(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin del analisis inicial:\n",
    "\n",
    "- Ahora hay que decidir como codificar las coordenadas geograficas // he valorado usar el clustering y la distancia a POI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_d7d2e593345c3592f0b80576e37d581f {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_d7d2e593345c3592f0b80576e37d581f&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_d7d2e593345c3592f0b80576e37d581f = L.map(\n",
       "                &quot;map_d7d2e593345c3592f0b80576e37d581f&quot;,\n",
       "                {\n",
       "                    center: [40.71427, -74.00597],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 10,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_479240b00c3c511e3e0f78039125d165 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_479240b00c3c511e3e0f78039125d165.addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_0325b2ea1e254169e6f0f0fcb0e40df1 = L.circleMarker(\n",
       "                [40.77213, -73.98665],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_fad1169873b7a30a76e7964c7879b955 = L.circleMarker(\n",
       "                [40.7198, -73.98566],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_5522fd410dcd3c2e0e80a48616729c35 = L.circleMarker(\n",
       "                [40.72197, -74.00633],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_2bffafd017b9cd4f3cff1a0f482fea40 = L.circleMarker(\n",
       "                [40.71162, -74.01693],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_5c102e81b41bcebb7d65b9a3120e32bd = L.circleMarker(\n",
       "                [40.65724, -73.9245],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_3fa189d3f1668df332bf8683d8262e43 = L.circleMarker(\n",
       "                [40.7506, -74.00388],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_62507366ec8d57c5e3f941198cb2ed29 = L.circleMarker(\n",
       "                [40.76835, -73.98367],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_d4ed4aba75a6c5937747a80d4517ab8f = L.circleMarker(\n",
       "                [40.71206, -74.00999],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c594c41d6fcf3a761e17abf3ed5d9436 = L.circleMarker(\n",
       "                [40.78517, -73.9527],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c3fffc87bf678408cf13da1d8e0fb840 = L.circleMarker(\n",
       "                [40.74482, -73.98367],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_0e2244840f30abad8cc6688709a76319 = L.circleMarker(\n",
       "                [40.68185, -73.88128],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_37660d0e2be9e488dfb39a1687a78ef6 = L.circleMarker(\n",
       "                [40.68742, -73.91957],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_2ac44730f0ce7187c164e5a236a159d7 = L.circleMarker(\n",
       "                [40.82511, -73.94961],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c764069995b02d1cfc919000fd8edfef = L.circleMarker(\n",
       "                [40.71705, -73.9647],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_d24352fcec7f826f2cae5854cc8e0a9a = L.circleMarker(\n",
       "                [40.68807, -73.95426],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_8520240769a496067e49ca5ef103b972 = L.circleMarker(\n",
       "                [40.74888, -74.00481],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_98de514ab65bfc49d57ea1f6a54fb3cb = L.circleMarker(\n",
       "                [40.76043, -73.99132],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_6bb21d4b668daddc77fe988191016a19 = L.circleMarker(\n",
       "                [40.733, -73.99413],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_e1e3d1b6175d236980ed4985813299a2 = L.circleMarker(\n",
       "                [40.71364, -74.01758],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_0c17d6eddeb1eb3da7c0a2193037dab9 = L.circleMarker(\n",
       "                [40.78545, -73.97123],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_9e83db3d03b718de8d528d335de48788 = L.circleMarker(\n",
       "                [40.76519, -73.96874],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_078c36bac3a5edc48f5d8c3e67dd4678 = L.circleMarker(\n",
       "                [40.72779, -73.98644],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_fc1b1c6435538b678adac193a0469c05 = L.circleMarker(\n",
       "                [40.78742, -73.97011],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_3a495cf1c17609923a01ceab15bf566e = L.circleMarker(\n",
       "                [40.74913, -74.00373],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_562e2dd445e034e3353959aa64d59e94 = L.circleMarker(\n",
       "                [40.81315, -73.9511],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_71dea18a926f84c0c0f2ccd54e98247f = L.circleMarker(\n",
       "                [40.58363, -73.96405],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_3e8c8c23bd0ba3d61effc8c443e15571 = L.circleMarker(\n",
       "                [40.72605, -74.00572],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_e52b299073a2b2e3b230ff1689d24631 = L.circleMarker(\n",
       "                [40.73652, -73.98618],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_1f0836132467647eb8c16237dc23c651 = L.circleMarker(\n",
       "                [40.73851, -73.99213],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_4ca4bcde2bf76e8c122a00006afdcf2a = L.circleMarker(\n",
       "                [40.76006, -73.98589],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_83ff0debceb67c7548a186dd5f9ff4d2 = L.circleMarker(\n",
       "                [40.70706, -74.00991],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_b488e33c22c9722f844a582a8d7f7d92 = L.circleMarker(\n",
       "                [40.79009, -73.97544],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_9e217d1d4ebc1f1947a1d689e8742d76 = L.circleMarker(\n",
       "                [40.75533, -73.99866],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_bc233f35539cc62c98e6dbcf6cc394e5 = L.circleMarker(\n",
       "                [40.73999, -73.99806],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_61bf93873160c8c50f319a4e2a3ed712 = L.circleMarker(\n",
       "                [40.72233, -73.99574],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_595bf697b36eba4cabfdbfb62954eff2 = L.circleMarker(\n",
       "                [40.7354, -74.00208],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c0d72a1c5586aad7758c4e2710214802 = L.circleMarker(\n",
       "                [40.67859, -73.97787],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_38c874707ba31fd06645c47cbaf7da35 = L.circleMarker(\n",
       "                [40.77811, -73.77069],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c2119ff6da0e5a0179e87e8655a28aea = L.circleMarker(\n",
       "                [40.66249, -73.95075],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_3b683f41c86b8c7bcece1cf154999982 = L.circleMarker(\n",
       "                [40.8016, -73.96409],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_481e4c170a971f08a92e17e78fade7f5 = L.circleMarker(\n",
       "                [40.88671, -73.9151],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c3b7f52d6d278371b2f2ab910d2f5d3c = L.circleMarker(\n",
       "                [40.71653, -73.96276],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_a2c1fffe58fd4a9b24a1d5276145b814 = L.circleMarker(\n",
       "                [40.82263, -73.95181],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_683423ee98fc67fabad5b474d60a53ef = L.circleMarker(\n",
       "                [40.67015, -73.94782],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_3b18c543514f62d899235fcea704ca21 = L.circleMarker(\n",
       "                [40.75535, -73.99502],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_74aa05ace54ce5657af688e70a1b4a13 = L.circleMarker(\n",
       "                [40.76481, -73.98845],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_36d6e1e3f5c0695f691e4d00442beb70 = L.circleMarker(\n",
       "                [40.67829, -73.96899],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_71f01958496da8f61ef173153a26645d = L.circleMarker(\n",
       "                [40.75081, -74.00396],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_f8ea8677a71c8888a714bbf1d679e6ef = L.circleMarker(\n",
       "                [40.71846, -73.9616],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_005c187cf23f82103bba74b05af59d10 = L.circleMarker(\n",
       "                [40.71546, -74.00856],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_24607878d0c5ede1347ed97053b4dc28 = L.circleMarker(\n",
       "                [40.74869, -73.94294],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_ad8c3ecf0a478ff514018c0cfe1f3ba3 = L.circleMarker(\n",
       "                [40.76024, -73.97483],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_336938b262d6b843b8acc2b6cbffe2ee = L.circleMarker(\n",
       "                [40.78132, -73.95262],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_0900d44d71213f49e8a823cf370b4385 = L.circleMarker(\n",
       "                [40.71782, -74.01047],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c86b7a9292721111099591212c4b3213 = L.circleMarker(\n",
       "                [40.73676, -73.9842],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_62c634e907b7f257e3496942522241de = L.circleMarker(\n",
       "                [40.72724, -73.97601],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_f82c4cd3e2cda133bc4ad278b2efe8a7 = L.circleMarker(\n",
       "                [40.6336, -74.02884],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_a896be618a0fe0b2571468ee80541f81 = L.circleMarker(\n",
       "                [40.73037, -74.00497],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_ab7e1c97b1ab17d0261ac7c723d09a01 = L.circleMarker(\n",
       "                [40.7256, -73.99487],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_105945590f9d119f76ae397fe6c2f993 = L.circleMarker(\n",
       "                [40.68187, -73.97075],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_50cc27d1a022c9178539aabc444230c8 = L.circleMarker(\n",
       "                [40.68929, -73.99656],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_a5e6380de6dc5f2288e7077978bb3317 = L.circleMarker(\n",
       "                [40.73942, -73.98648],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_5c3454fc89e0ef4bb188eb9c423ca7db = L.circleMarker(\n",
       "                [40.68245, -73.93417],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_8a93b1293154e3be2656470150aa1ca6 = L.circleMarker(\n",
       "                [40.62724, -73.93043],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_46a168e935a9b70a2183e837b17de8c0 = L.circleMarker(\n",
       "                [40.70662, -74.00562],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_ce3c3d5e5322aafeb6f345045fb6c440 = L.circleMarker(\n",
       "                [40.72208, -73.98472],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_b82daa99a2d1928342255bc7ceb0a85a = L.circleMarker(\n",
       "                [40.67862, -73.97065],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_9001acabe5dd1b07f94787b547dfcb97 = L.circleMarker(\n",
       "                [40.72194, -73.95511],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_0f945548e9ee915021fef3fb491c5496 = L.circleMarker(\n",
       "                [40.7542, -73.96815],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_0e8f28004ba234904ea566e7fb5d580c = L.circleMarker(\n",
       "                [40.73983, -74.00586],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_ae6b9e4fa0e8ef94efe0c6d0393e1a9d = L.circleMarker(\n",
       "                [40.74982, -73.8061],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_fb98b06a0c85906dbcf7a17106e551b9 = L.circleMarker(\n",
       "                [40.58781, -73.79317],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_847e4a6dbbb2bbb909eeaed3fec3fe04 = L.circleMarker(\n",
       "                [40.72015, -74.00435],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_cd49d67da73e6b68aa8d06f3e6fdca63 = L.circleMarker(\n",
       "                [40.80323, -73.94253],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_908bb0810ec04b6a20faa78bb7bb78ca = L.circleMarker(\n",
       "                [40.76075, -73.99837],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_4b21f084cc22d47b9d8fab63c7029047 = L.circleMarker(\n",
       "                [40.75021, -74.00479],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c5a204ab29174712086415e374099bbc = L.circleMarker(\n",
       "                [40.80646, -73.9517],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_567101f631bd575ff4cbeed6b396543a = L.circleMarker(\n",
       "                [40.73722, -74.00263],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_36f16a44976ec944fc92bf4bfe4b7e08 = L.circleMarker(\n",
       "                [40.73151, -74.00528],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_36b44a8f7b0d0b9c3ba751df439667b9 = L.circleMarker(\n",
       "                [40.71722, -74.00293],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_66ff89077d25fe926ec5473f121dd55d = L.circleMarker(\n",
       "                [40.76789, -73.93512],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_d10e17fc4c5e5f045d1ba39d7f0895e5 = L.circleMarker(\n",
       "                [40.72997, -73.9884],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_640ccf2702d96a710d7e1fd93442abb0 = L.circleMarker(\n",
       "                [40.6758, -73.95091],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_2e8bda0c20d19e447be099d99f45fad8 = L.circleMarker(\n",
       "                [40.76262, -73.96443],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_238982cdfc16c49749bed0eb37e17d66 = L.circleMarker(\n",
       "                [40.6776, -73.96961],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_36a70e26cb5cc014e0ded0442d7c371b = L.circleMarker(\n",
       "                [40.66085, -73.95586],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_2fde1d368ebe284b27a8a7b4c0d5459e = L.circleMarker(\n",
       "                [40.68767, -73.95805],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_36698659768612aa97f0460aaee8f64e = L.circleMarker(\n",
       "                [40.69202, -73.95456],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_8df442693172dd4193568e73215488c5 = L.circleMarker(\n",
       "                [40.80146, -73.96076],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_ef3f222da8f64dc0befecef0e3ee5ee1 = L.circleMarker(\n",
       "                [40.68494, -73.9885],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_3c554993ba5d20201fde62c6b1fdef1b = L.circleMarker(\n",
       "                [40.57919, -74.00635],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_3280a54bf0d2d22752ff399c41d97333 = L.circleMarker(\n",
       "                [40.7206, -74.00023],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_36552b8184b71ac8b479c3b36255a3b1 = L.circleMarker(\n",
       "                [40.72525, -74.00142],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_f667448dac7c5fd99c8ea10b8c1b877e = L.circleMarker(\n",
       "                [40.72273, -74.00479],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_af3c3a1a890e89dbcb27dbf94c6e7260 = L.circleMarker(\n",
       "                [40.75359, -73.97325],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_c1012051f1f10df7edd50476ba6dc445 = L.circleMarker(\n",
       "                [40.74786, -73.94628],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_753e9964fa37bde259567cfe0cec9c6d = L.circleMarker(\n",
       "                [40.72367, -73.99868],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_2f0dff34892021db711cb74ebd16503a = L.circleMarker(\n",
       "                [40.77534, -73.95287],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_cb25f10dcc4407ff3b32f30e8b9a72a8 = L.circleMarker(\n",
       "                [40.53076, -74.20295],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_567baf8e42747aaa495aff8dd8c2768a = L.circleMarker(\n",
       "                [40.73546, -73.98057],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;#3388ff&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: false, &quot;fillColor&quot;: &quot;#3388ff&quot;, &quot;fillOpacity&quot;: 0.2, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1.0, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "            var circle_marker_e9f6a71d6b7f9ed1bbf34c6865c9a2a6 = L.circleMarker(\n",
       "                [40.71427, -74.00597],\n",
       "                {&quot;bubblingMouseEvents&quot;: true, &quot;color&quot;: &quot;black&quot;, &quot;dashArray&quot;: null, &quot;dashOffset&quot;: null, &quot;fill&quot;: true, &quot;fillColor&quot;: &quot;red&quot;, &quot;fillOpacity&quot;: 1, &quot;fillRule&quot;: &quot;evenodd&quot;, &quot;lineCap&quot;: &quot;round&quot;, &quot;lineJoin&quot;: &quot;round&quot;, &quot;opacity&quot;: 1, &quot;radius&quot;: 10, &quot;stroke&quot;: true, &quot;weight&quot;: 3}\n",
       "            ).addTo(map_d7d2e593345c3592f0b80576e37d581f);\n",
       "        \n",
       "    \n",
       "        var popup_609838ddc31ea2c121afaadc43538e86 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_2db4fc997d91fbb7684f4f8d6618fe6f = $(`&lt;div id=&quot;html_2db4fc997d91fbb7684f4f8d6618fe6f&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;10 pixels&lt;/div&gt;`)[0];\n",
       "                popup_609838ddc31ea2c121afaadc43538e86.setContent(html_2db4fc997d91fbb7684f4f8d6618fe6f);\n",
       "            \n",
       "        \n",
       "\n",
       "        circle_marker_e9f6a71d6b7f9ed1bbf34c6865c9a2a6.bindPopup(popup_609838ddc31ea2c121afaadc43538e86)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            circle_marker_e9f6a71d6b7f9ed1bbf34c6865c9a2a6.bindTooltip(\n",
       "                `&lt;div&gt;\n",
       "                     I am in pixels\n",
       "                 &lt;/div&gt;`,\n",
       "                {&quot;sticky&quot;: true}\n",
       "            );\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7f5fb06ff400>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distancia a POI (centro de new york)\n",
    "# En primer lugar confirmo que los precios mas altos estan en torno al dentro geografico de la cuidad\n",
    "\n",
    "# Encontramos los 100 precios mas altos \n",
    "df_reset = df.reset_index(drop=True) # Conveniente despues de haber estado filtrando y eliminando filas para poder acceder a los indices que obtendremos\n",
    "# Hallamos los 100 valores mas altos con nlargest y sus indices dentro de dataframe con .index\n",
    "top100_indices = df_reset['LOG_PRICE'].nlargest(100).index \n",
    "# Dataframe con esos valores\n",
    "df_top100 = df_reset.iloc[top100_indices]\n",
    "\n",
    "\n",
    "# importamos la libreria que nos permitira ver esos valores en el plano\n",
    "import folium\n",
    "\n",
    "# Creamos el plano y definimos su posicion inicial\n",
    "mapa_top_100 = folium.Map(location=[40.71427 , -74.00597]) # Centro de NY segun GMaps\n",
    "\n",
    "# Añadimos los 100 valores maximos de precio al plano con sus coordenadas\n",
    "df_top100.apply(lambda row:folium.CircleMarker(location=[row[\"latitude\"], row[\"longitude\"]] ).add_to(mapa_top_100), axis=1)\n",
    "\n",
    "# Creamos un punto con las coordenadas del centro de la ciudad\n",
    "folium.CircleMarker(\n",
    "    location=[40.71427 , -74.00597],\n",
    "    radius=10,\n",
    "    color=\"black\",\n",
    "    stroke=True,\n",
    "    fill=True,\n",
    "    fill_opacity=1,\n",
    "    fill_color='red',\n",
    "    opacity=1,\n",
    "    popup=\"{} pixels\".format(10),\n",
    "    tooltip=\"I am in pixels\",\n",
    ").add_to(mapa_top_100)\n",
    "\n",
    "# Mostramos el mapa\n",
    "mapa_top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmado que los mayores precios estan en su mayoria proximos al centro procedemos con la codificacion por distancia a punto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificacion de las variables latitude y longitude // Aplicamos la codificacion basada en distancia a POI\n",
    "\n",
    "# Coordenadas del centro de NY (latitud y longitud)\n",
    "lat_centro, lon_centro = 40.71427 , -74.00597   # Centro de Nueva York\n",
    "\n",
    "# Creamos la columna que referencia la distancia de cada habitacion al centro // No es mas que la formula de la distancia euclidiana // \n",
    "# Se usa este metodo porque en distancias tan cortas la curvatura de la tierra es despreciable\n",
    "df['distance_to_center'] = np.sqrt((df['latitude'] - lat_centro)**2 + (df['longitude'] - lon_centro)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La segunda posibilidad para codificar las coordenadas geograficas es el clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ahora a por el segundo metodo // clustering\n",
    "\n",
    "# Se aplica el metodo del codo para hallar el numero optimo de clusteres\n",
    "Suma_error_cuadratico = []\n",
    "for k in range(1, 25):  # probaremos de 1 a 24 clusters siendo k el numero de clusters\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42) # Se crea una instancia de kmeans para cada valor de k\n",
    "    kmeans.fit(df[['latitude', 'longitude']])      # Se aplica kmeans a las coordenadas geograficas\n",
    "    Suma_error_cuadratico.append(kmeans.inertia_)  # añadimos las distancias**2 hasta el centroide mas cercano a la suma total a la lista vacia inicializada antes (Suma_error_cuadratico)\n",
    "\n",
    "# Ploteamos la lista obtenida dentro de los clusters en función del número de clusters\n",
    "plt.plot(range(1, 25), Suma_error_cuadratico, marker='o')\n",
    "plt.title('Método del Codo')\n",
    "plt.xlabel('Número de Clusters')\n",
    "plt.ylabel('Suma de error')\n",
    "plt.show()\n",
    "\n",
    "# Me quedo con 14 clusters para la codificacion de las coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "coords_cluster\n",
       "6     7059\n",
       "0     5974\n",
       "1     5364\n",
       "4     5050\n",
       "7     5001\n",
       "11    4949\n",
       "3     3248\n",
       "5     2696\n",
       "12    2613\n",
       "10    1881\n",
       "2     1250\n",
       "9      687\n",
       "13     681\n",
       "8      271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos 14 clusters que definen grupos de localizaciones generalizadas en un solo valor\n",
    "kmeans = KMeans(14, random_state=42)\n",
    "clusters = kmeans.fit_predict(df[['latitude','longitude']])\n",
    "df['coords_cluster'] = kmeans.predict(df[['latitude','longitude']])\n",
    "df.coords_cluster.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>LOG_PRICE</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>coords_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-73.97</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  neighbourhood_group neighbourhood  latitude  longitude     room_type  \\\n",
       "0            Brooklyn    Kensington     40.65     -73.97  Private room   \n",
       "\n",
       "   minimum_nights  number_of_reviews  calculated_host_listings_count  \\\n",
       "0               1                  9                               6   \n",
       "\n",
       "   availability_365  LOG_PRICE  distance_to_center  coords_cluster  \n",
       "0               365       5.00                0.07              10  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- En primer lugar, para determinar que metodo de codificacion ha sido mas efectivo al capturar la informacion original, creamos un mapa de correlacion.\n",
    "- Ademas echaremos un vistazo al resto de correlaciones para empezar a filtrar columnas innecesarias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2421e_row0_col0, #T_2421e_row1_col1, #T_2421e_row2_col2, #T_2421e_row3_col3, #T_2421e_row4_col4, #T_2421e_row5_col5, #T_2421e_row6_col6, #T_2421e_row7_col7, #T_2421e_row8_col8 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row0_col1, #T_2421e_row1_col0, #T_2421e_row4_col5, #T_2421e_row4_col6, #T_2421e_row4_col8, #T_2421e_row5_col2, #T_2421e_row5_col4, #T_2421e_row6_col3, #T_2421e_row6_col7 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row0_col2 {\n",
       "  background-color: #92b4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row0_col3 {\n",
       "  background-color: #799cf8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row0_col4 {\n",
       "  background-color: #9bbcff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row0_col5 {\n",
       "  background-color: #81a4fb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row0_col6 {\n",
       "  background-color: #4e68d8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row0_col7 {\n",
       "  background-color: #5470de;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row0_col8 {\n",
       "  background-color: #7da0f9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row1_col2, #T_2421e_row1_col7 {\n",
       "  background-color: #485fd1;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row1_col3, #T_2421e_row6_col4 {\n",
       "  background-color: #7a9df8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row1_col4 {\n",
       "  background-color: #8badfd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row1_col5, #T_2421e_row1_col8, #T_2421e_row6_col8 {\n",
       "  background-color: #9fbfff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row1_col6 {\n",
       "  background-color: #5d7ce6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row2_col0, #T_2421e_row2_col3, #T_2421e_row3_col0, #T_2421e_row3_col1 {\n",
       "  background-color: #8caffe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row2_col1, #T_2421e_row5_col0 {\n",
       "  background-color: #4257c9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row2_col4 {\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row2_col5 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row2_col6 {\n",
       "  background-color: #445acc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row2_col7, #T_2421e_row7_col1 {\n",
       "  background-color: #516ddb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row2_col8 {\n",
       "  background-color: #7396f5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row3_col2 {\n",
       "  background-color: #a2c1ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row3_col4 {\n",
       "  background-color: #abc8fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row3_col5 {\n",
       "  background-color: #b1cbfc;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row3_col6 {\n",
       "  background-color: #4f69d9;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row3_col7, #T_2421e_row4_col1 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row3_col8 {\n",
       "  background-color: #a7c5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row4_col0, #T_2421e_row4_col3, #T_2421e_row7_col0, #T_2421e_row8_col3 {\n",
       "  background-color: #5e7de7;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row4_col2 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row4_col7, #T_2421e_row8_col7 {\n",
       "  background-color: #6485ec;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row5_col1 {\n",
       "  background-color: #6384eb;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row5_col3, #T_2421e_row8_col1 {\n",
       "  background-color: #6687ed;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row5_col6 {\n",
       "  background-color: #93b5fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row5_col7 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row5_col8 {\n",
       "  background-color: #e46e56;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row6_col0 {\n",
       "  background-color: #4c66d6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row6_col1 {\n",
       "  background-color: #5b7ae5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row6_col2 {\n",
       "  background-color: #4961d2;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row6_col5 {\n",
       "  background-color: #c4d5f3;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row7_col2 {\n",
       "  background-color: #6282ea;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row7_col3, #T_2421e_row8_col0 {\n",
       "  background-color: #4055c8;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row7_col4 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row7_col5 {\n",
       "  background-color: #cdd9ec;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row7_col6 {\n",
       "  background-color: #455cce;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row7_col8 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_2421e_row8_col2 {\n",
       "  background-color: #3d50c3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row8_col4 {\n",
       "  background-color: #3e51c5;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row8_col5 {\n",
       "  background-color: #e36c55;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_2421e_row8_col6 {\n",
       "  background-color: #6788ee;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2421e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2421e_level0_col0\" class=\"col_heading level0 col0\" >minimum_nights</th>\n",
       "      <th id=\"T_2421e_level0_col1\" class=\"col_heading level0 col1\" >number_of_reviews</th>\n",
       "      <th id=\"T_2421e_level0_col2\" class=\"col_heading level0 col2\" >calculated_host_listings_count</th>\n",
       "      <th id=\"T_2421e_level0_col3\" class=\"col_heading level0 col3\" >availability_365</th>\n",
       "      <th id=\"T_2421e_level0_col4\" class=\"col_heading level0 col4\" >LOG_PRICE</th>\n",
       "      <th id=\"T_2421e_level0_col5\" class=\"col_heading level0 col5\" >distance_to_center</th>\n",
       "      <th id=\"T_2421e_level0_col6\" class=\"col_heading level0 col6\" >coords_cluster</th>\n",
       "      <th id=\"T_2421e_level0_col7\" class=\"col_heading level0 col7\" >latitude</th>\n",
       "      <th id=\"T_2421e_level0_col8\" class=\"col_heading level0 col8\" >longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row0\" class=\"row_heading level0 row0\" >minimum_nights</th>\n",
       "      <td id=\"T_2421e_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
       "      <td id=\"T_2421e_row0_col1\" class=\"data row0 col1\" >-0.099</td>\n",
       "      <td id=\"T_2421e_row0_col2\" class=\"data row0 col2\" >0.172</td>\n",
       "      <td id=\"T_2421e_row0_col3\" class=\"data row0 col3\" >0.172</td>\n",
       "      <td id=\"T_2421e_row0_col4\" class=\"data row0 col4\" >0.028</td>\n",
       "      <td id=\"T_2421e_row0_col5\" class=\"data row0 col5\" >-0.073</td>\n",
       "      <td id=\"T_2421e_row0_col6\" class=\"data row0 col6\" >-0.033</td>\n",
       "      <td id=\"T_2421e_row0_col7\" class=\"data row0 col7\" >0.026</td>\n",
       "      <td id=\"T_2421e_row0_col8\" class=\"data row0 col8\" >-0.074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row1\" class=\"row_heading level0 row1\" >number_of_reviews</th>\n",
       "      <td id=\"T_2421e_row1_col0\" class=\"data row1 col0\" >-0.099</td>\n",
       "      <td id=\"T_2421e_row1_col1\" class=\"data row1 col1\" >1.000</td>\n",
       "      <td id=\"T_2421e_row1_col2\" class=\"data row1 col2\" >-0.073</td>\n",
       "      <td id=\"T_2421e_row1_col3\" class=\"data row1 col3\" >0.173</td>\n",
       "      <td id=\"T_2421e_row1_col4\" class=\"data row1 col4\" >-0.039</td>\n",
       "      <td id=\"T_2421e_row1_col5\" class=\"data row1 col5\" >0.044</td>\n",
       "      <td id=\"T_2421e_row1_col6\" class=\"data row1 col6\" >0.017</td>\n",
       "      <td id=\"T_2421e_row1_col7\" class=\"data row1 col7\" >-0.014</td>\n",
       "      <td id=\"T_2421e_row1_col8\" class=\"data row1 col8\" >0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row2\" class=\"row_heading level0 row2\" >calculated_host_listings_count</th>\n",
       "      <td id=\"T_2421e_row2_col0\" class=\"data row2 col0\" >0.172</td>\n",
       "      <td id=\"T_2421e_row2_col1\" class=\"data row2 col1\" >-0.073</td>\n",
       "      <td id=\"T_2421e_row2_col2\" class=\"data row2 col2\" >1.000</td>\n",
       "      <td id=\"T_2421e_row2_col3\" class=\"data row2 col3\" >0.226</td>\n",
       "      <td id=\"T_2421e_row2_col4\" class=\"data row2 col4\" >0.134</td>\n",
       "      <td id=\"T_2421e_row2_col5\" class=\"data row2 col5\" >-0.123</td>\n",
       "      <td id=\"T_2421e_row2_col6\" class=\"data row2 col6\" >-0.068</td>\n",
       "      <td id=\"T_2421e_row2_col7\" class=\"data row2 col7\" >0.019</td>\n",
       "      <td id=\"T_2421e_row2_col8\" class=\"data row2 col8\" >-0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row3\" class=\"row_heading level0 row3\" >availability_365</th>\n",
       "      <td id=\"T_2421e_row3_col0\" class=\"data row3 col0\" >0.172</td>\n",
       "      <td id=\"T_2421e_row3_col1\" class=\"data row3 col1\" >0.173</td>\n",
       "      <td id=\"T_2421e_row3_col2\" class=\"data row3 col2\" >0.226</td>\n",
       "      <td id=\"T_2421e_row3_col3\" class=\"data row3 col3\" >1.000</td>\n",
       "      <td id=\"T_2421e_row3_col4\" class=\"data row3 col4\" >0.091</td>\n",
       "      <td id=\"T_2421e_row3_col5\" class=\"data row3 col5\" >0.115</td>\n",
       "      <td id=\"T_2421e_row3_col6\" class=\"data row3 col6\" >-0.028</td>\n",
       "      <td id=\"T_2421e_row3_col7\" class=\"data row3 col7\" >-0.007</td>\n",
       "      <td id=\"T_2421e_row3_col8\" class=\"data row3 col8\" >0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row4\" class=\"row_heading level0 row4\" >LOG_PRICE</th>\n",
       "      <td id=\"T_2421e_row4_col0\" class=\"data row4 col0\" >0.028</td>\n",
       "      <td id=\"T_2421e_row4_col1\" class=\"data row4 col1\" >-0.039</td>\n",
       "      <td id=\"T_2421e_row4_col2\" class=\"data row4 col2\" >0.134</td>\n",
       "      <td id=\"T_2421e_row4_col3\" class=\"data row4 col3\" >0.091</td>\n",
       "      <td id=\"T_2421e_row4_col4\" class=\"data row4 col4\" >1.000</td>\n",
       "      <td id=\"T_2421e_row4_col5\" class=\"data row4 col5\" >-0.373</td>\n",
       "      <td id=\"T_2421e_row4_col6\" class=\"data row4 col6\" >-0.104</td>\n",
       "      <td id=\"T_2421e_row4_col7\" class=\"data row4 col7\" >0.080</td>\n",
       "      <td id=\"T_2421e_row4_col8\" class=\"data row4 col8\" >-0.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row5\" class=\"row_heading level0 row5\" >distance_to_center</th>\n",
       "      <td id=\"T_2421e_row5_col0\" class=\"data row5 col0\" >-0.073</td>\n",
       "      <td id=\"T_2421e_row5_col1\" class=\"data row5 col1\" >0.044</td>\n",
       "      <td id=\"T_2421e_row5_col2\" class=\"data row5 col2\" >-0.123</td>\n",
       "      <td id=\"T_2421e_row5_col3\" class=\"data row5 col3\" >0.115</td>\n",
       "      <td id=\"T_2421e_row5_col4\" class=\"data row5 col4\" >-0.373</td>\n",
       "      <td id=\"T_2421e_row5_col5\" class=\"data row5 col5\" >1.000</td>\n",
       "      <td id=\"T_2421e_row5_col6\" class=\"data row5 col6\" >0.193</td>\n",
       "      <td id=\"T_2421e_row5_col7\" class=\"data row5 col7\" >0.234</td>\n",
       "      <td id=\"T_2421e_row5_col8\" class=\"data row5 col8\" >0.793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row6\" class=\"row_heading level0 row6\" >coords_cluster</th>\n",
       "      <td id=\"T_2421e_row6_col0\" class=\"data row6 col0\" >-0.033</td>\n",
       "      <td id=\"T_2421e_row6_col1\" class=\"data row6 col1\" >0.017</td>\n",
       "      <td id=\"T_2421e_row6_col2\" class=\"data row6 col2\" >-0.068</td>\n",
       "      <td id=\"T_2421e_row6_col3\" class=\"data row6 col3\" >-0.028</td>\n",
       "      <td id=\"T_2421e_row6_col4\" class=\"data row6 col4\" >-0.104</td>\n",
       "      <td id=\"T_2421e_row6_col5\" class=\"data row6 col5\" >0.193</td>\n",
       "      <td id=\"T_2421e_row6_col6\" class=\"data row6 col6\" >1.000</td>\n",
       "      <td id=\"T_2421e_row6_col7\" class=\"data row6 col7\" >-0.063</td>\n",
       "      <td id=\"T_2421e_row6_col8\" class=\"data row6 col8\" >0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row7\" class=\"row_heading level0 row7\" >latitude</th>\n",
       "      <td id=\"T_2421e_row7_col0\" class=\"data row7 col0\" >0.026</td>\n",
       "      <td id=\"T_2421e_row7_col1\" class=\"data row7 col1\" >-0.014</td>\n",
       "      <td id=\"T_2421e_row7_col2\" class=\"data row7 col2\" >0.019</td>\n",
       "      <td id=\"T_2421e_row7_col3\" class=\"data row7 col3\" >-0.007</td>\n",
       "      <td id=\"T_2421e_row7_col4\" class=\"data row7 col4\" >0.080</td>\n",
       "      <td id=\"T_2421e_row7_col5\" class=\"data row7 col5\" >0.234</td>\n",
       "      <td id=\"T_2421e_row7_col6\" class=\"data row7 col6\" >-0.063</td>\n",
       "      <td id=\"T_2421e_row7_col7\" class=\"data row7 col7\" >1.000</td>\n",
       "      <td id=\"T_2421e_row7_col8\" class=\"data row7 col8\" >0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2421e_level0_row8\" class=\"row_heading level0 row8\" >longitude</th>\n",
       "      <td id=\"T_2421e_row8_col0\" class=\"data row8 col0\" >-0.074</td>\n",
       "      <td id=\"T_2421e_row8_col1\" class=\"data row8 col1\" >0.054</td>\n",
       "      <td id=\"T_2421e_row8_col2\" class=\"data row8 col2\" >-0.113</td>\n",
       "      <td id=\"T_2421e_row8_col3\" class=\"data row8 col3\" >0.089</td>\n",
       "      <td id=\"T_2421e_row8_col4\" class=\"data row8 col4\" >-0.353</td>\n",
       "      <td id=\"T_2421e_row8_col5\" class=\"data row8 col5\" >0.793</td>\n",
       "      <td id=\"T_2421e_row8_col6\" class=\"data row8 col6\" >0.054</td>\n",
       "      <td id=\"T_2421e_row8_col7\" class=\"data row8 col7\" >0.082</td>\n",
       "      <td id=\"T_2421e_row8_col8\" class=\"data row8 col8\" >1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5faf8d6080>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos el mapa de correlaciones\n",
    "# Filtramos por variables numericas\n",
    "columns_for_corr = ['minimum_nights','number_of_reviews','calculated_host_listings_count',\t'availability_365',\t'LOG_PRICE','distance_to_center','coords_cluster', 'latitude','longitude'] \n",
    "df_for_corr = df[columns_for_corr] \n",
    "# Mapa de correlacion\n",
    "corr = df_for_corr.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').format(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- El clustering de coordenadas tiene menor correlacion con el precio que la distancia al centro //  se elimina y nos quedamos con la distancia al centro\n",
    "\n",
    "- Se eliminan las columnas originales de coordenadas geograficas\n",
    "\n",
    "- Minimum_nights, number_of_reviews, availability_365 tampoco tienen  apenas correlacion con el precio // se eliminan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_eliminar = ['longitude', 'latitude']\n",
    "df = df.drop(columnas_a_eliminar, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####                                Las variables numericas preparadas. vamos a por las categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nunique</th>\n",
       "      <th>nulls</th>\n",
       "      <th>percent_nulls</th>\n",
       "      <th>Dtype</th>\n",
       "      <th>non_null</th>\n",
       "      <th>total_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighbourhood</th>\n",
       "      <td>218</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>room_type</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>object</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minimum_nights</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_reviews</th>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability_365</th>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOG_PRICE</th>\n",
       "      <td>628</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distance_to_center</th>\n",
       "      <td>46694</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>float64</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords_cluster</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>int32</td>\n",
       "      <td>46724</td>\n",
       "      <td>46724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                nunique  nulls  percent_nulls    Dtype  \\\n",
       "neighbourhood_group                   5      0           0.00   object   \n",
       "neighbourhood                       218      0           0.00   object   \n",
       "room_type                             3      0           0.00   object   \n",
       "minimum_nights                       97      0           0.00    int64   \n",
       "number_of_reviews                   363      0           0.00    int64   \n",
       "calculated_host_listings_count       47      0           0.00    int64   \n",
       "availability_365                    366      0           0.00    int64   \n",
       "LOG_PRICE                           628      0           0.00  float64   \n",
       "distance_to_center                46694      0           0.00  float64   \n",
       "coords_cluster                       14      0           0.00    int32   \n",
       "\n",
       "                                non_null  total_values  \n",
       "neighbourhood_group                46724         46724  \n",
       "neighbourhood                      46724         46724  \n",
       "room_type                          46724         46724  \n",
       "minimum_nights                     46724         46724  \n",
       "number_of_reviews                  46724         46724  \n",
       "calculated_host_listings_count     46724         46724  \n",
       "availability_365                   46724         46724  \n",
       "LOG_PRICE                          46724         46724  \n",
       "distance_to_center                 46724         46724  \n",
       "coords_cluster                     46724         46724  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dtype\n",
       "int64      4\n",
       "object     3\n",
       "float64    2\n",
       "int32      1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataframe tiene 46724 filas y 10 columnas\n",
      "Hay 0 valores duplicados\n"
     ]
    }
   ],
   "source": [
    "# Compruebo como queda el dataframe\n",
    "df_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimino valor duplicado\n",
    "df.drop_duplicates(inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>LOG_PRICE</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>coords_cluster</th>\n",
       "      <th>encoded_neighbourhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10</td>\n",
       "      <td>4.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>Private room</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11</td>\n",
       "      <td>4.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46719</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46720</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bushwick</td>\n",
       "      <td>Private room</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46721</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.74</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46722</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>Shared room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46723</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>Private room</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46724 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neighbourhood_group       neighbourhood        room_type  \\\n",
       "0                Brooklyn          Kensington     Private room   \n",
       "1               Manhattan             Midtown  Entire home/apt   \n",
       "2               Manhattan              Harlem     Private room   \n",
       "3                Brooklyn        Clinton Hill  Entire home/apt   \n",
       "4               Manhattan         East Harlem  Entire home/apt   \n",
       "...                   ...                 ...              ...   \n",
       "46719            Brooklyn  Bedford-Stuyvesant     Private room   \n",
       "46720            Brooklyn            Bushwick     Private room   \n",
       "46721           Manhattan              Harlem  Entire home/apt   \n",
       "46722           Manhattan      Hell's Kitchen      Shared room   \n",
       "46723           Manhattan      Hell's Kitchen     Private room   \n",
       "\n",
       "       minimum_nights  number_of_reviews  calculated_host_listings_count  \\\n",
       "0                   1                  9                               6   \n",
       "1                   1                 45                               2   \n",
       "2                   3                  0                               1   \n",
       "3                   1                270                               1   \n",
       "4                  10                  9                               1   \n",
       "...               ...                ...                             ...   \n",
       "46719               2                  0                               2   \n",
       "46720               4                  0                               2   \n",
       "46721              10                  0                               1   \n",
       "46722               1                  0                               6   \n",
       "46723               7                  0                               1   \n",
       "\n",
       "       availability_365  LOG_PRICE  distance_to_center  coords_cluster  \\\n",
       "0                   365       5.00                0.07              10   \n",
       "1                   355       5.42                0.05               0   \n",
       "2                   365       5.01                0.11               3   \n",
       "3                   194       4.49                0.05               1   \n",
       "4                     0       4.38                0.10              11   \n",
       "...                 ...        ...                 ...             ...   \n",
       "46719                 9       4.25                0.07               1   \n",
       "46720                36       3.69                0.07               7   \n",
       "46721                27       4.74                0.12               3   \n",
       "46722                 2       4.01                0.05               0   \n",
       "46723                23       4.50                0.05               0   \n",
       "\n",
       "       encoded_neighbourhood  \n",
       "0                       4.34  \n",
       "1                       5.38  \n",
       "2                       4.56  \n",
       "3                       4.77  \n",
       "4                       4.63  \n",
       "...                      ...  \n",
       "46719                   4.44  \n",
       "46720                   4.26  \n",
       "46721                   4.56  \n",
       "46722                   5.12  \n",
       "46723                   5.12  \n",
       "\n",
       "[46724 rows x 11 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Me ha costado la vida, pero he creado esta funcion para hacer target encoding en el futuro facilmente\n",
    "def target_encoding(dataframe, column, target_column, smooth_coef=0):\n",
    "    column, target_column = str(column), str(target_column)\n",
    "    conteo_columna = dataframe.groupby(column)[target_column].count().reset_index(name= 'conteo')\n",
    "    # Calculamos el promedio de LOGPRICE por vecindario\n",
    "    promedio_columna = dataframe.groupby(column)[target_column].mean().reset_index(name= 'column_mean')\n",
    "    # Unimos conteo y promedio en el mismo DF en base al vecindario\n",
    "    final_df = promedio_columna.merge(conteo_columna, on=column)\n",
    "    # Hallamos el promedio global \n",
    "    global_mean = dataframe[target_column].mean()\n",
    "    # Asignamos coeficiente de suavizado\n",
    "    m = smooth_coef\n",
    "    # Calculamos precio suavizado para cada vecindario\n",
    "    final_df[f'encoded_{column}'] = (final_df['conteo'] * final_df['column_mean'] + m * global_mean) / final_df['conteo'] + m\n",
    "    # Creamos un diccionario para poder relacionar cada promedio con su valor original mas adelante\n",
    "    encoded_value_dict = pd.Series(final_df[f'encoded_{column}'].values, index= final_df[column]).to_dict()\n",
    "    # Fusionamos el dataframe original con el dataframe vecindarios en base a la columna 'neighbourhood'\n",
    "    result_df = dataframe.merge(final_df[[column,str(f'encoded_{column}')]], on=column, how='left')\n",
    "    return result_df\n",
    "\n",
    "df = target_encoding(df, 'neighbourhood', 'LOG_PRICE' )\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Contamos el número de entradas por vecindario\\nconteo_vecindarios = df.groupby('neighbourhood')['LOG_PRICE'].count().reset_index(name= 'conteo')\\n# Calculamos el promedio de LOGPRICE por vecindario\\npromedio = df.groupby('neighbourhood')['LOG_PRICE'].mean().reset_index(name= 'mean_price')\\n# Unimos conteo y promedio en el mismo DF en base al vecindario\\nvecindarios = promedio.merge(conteo_vecindarios, on='neighbourhood')\\n# Hallamos el promedio global de LOG_PRICE\\nprecio_medio_global = df.LOG_PRICE.mean()\\n# Asignamos coeficiente de suavizado\\nm = 3\\n# Calculamos precio suavizado para cada vecindario\\nvecindarios['neighbourhood_price_smoothed'] = (vecindarios.conteo * vecindarios.mean_price + m * precio_medio_global) / vecindarios.conteo + m\\n# Creamos un diccionario para poder relacionar cada promedio con su vecindario mas adelante\\nvecindarios_codificado = pd.Series(vecindarios.neighbourhood_price_smoothed.values, index= vecindarios.neighbourhood).to_dict()\\n# Fusionamos el dataframe original con el dataframe vecindarios en base a la columna 'neighbourhood'\\ndf = df.merge(vecindarios[['neighbourhood','neighbourhood_price_smoothed']], on='neighbourhood', how='left')\\ndf.head(1)\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Este es el codigo original a partir del cual he creado la funcion\n",
    "# Target Encoding para codificar la columna neighbourhood // al contar con 218 valores unicos, descarto one_hot. El label encoding por su parte, aportaria una 'ordinalidad' artificial a los valores originales.\n",
    "\n",
    "'''# Contamos el número de entradas por vecindario\n",
    "conteo_vecindarios = df.groupby('neighbourhood')['LOG_PRICE'].count().reset_index(name= 'conteo')\n",
    "# Calculamos el promedio de LOGPRICE por vecindario\n",
    "promedio = df.groupby('neighbourhood')['LOG_PRICE'].mean().reset_index(name= 'mean_price')\n",
    "# Unimos conteo y promedio en el mismo DF en base al vecindario\n",
    "vecindarios = promedio.merge(conteo_vecindarios, on='neighbourhood')\n",
    "# Hallamos el promedio global de LOG_PRICE\n",
    "precio_medio_global = df.LOG_PRICE.mean()\n",
    "# Asignamos coeficiente de suavizado\n",
    "m = 3\n",
    "# Calculamos precio suavizado para cada vecindario\n",
    "vecindarios['neighbourhood_price_smoothed'] = (vecindarios.conteo * vecindarios.mean_price + m * precio_medio_global) / vecindarios.conteo + m\n",
    "# Creamos un diccionario para poder relacionar cada promedio con su vecindario mas adelante\n",
    "vecindarios_codificado = pd.Series(vecindarios.neighbourhood_price_smoothed.values, index= vecindarios.neighbourhood).to_dict()\n",
    "# Fusionamos el dataframe original con el dataframe vecindarios en base a la columna 'neighbourhood'\n",
    "df = df.merge(vecindarios[['neighbourhood','neighbourhood_price_smoothed']], on='neighbourhood', how='left')\n",
    "df.head(1)'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_354ad_row0_col0, #T_354ad_row1_col1, #T_354ad_row2_col2, #T_354ad_row3_col3 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_354ad_row0_col1 {\n",
       "  background-color: #b6cefa;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_354ad_row0_col2 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_354ad_row0_col3 {\n",
       "  background-color: #e1dad6;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_354ad_row1_col0 {\n",
       "  background-color: #85a8fc;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_354ad_row1_col2 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_354ad_row1_col3 {\n",
       "  background-color: #f6a586;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_354ad_row2_col0, #T_354ad_row2_col1, #T_354ad_row2_col3, #T_354ad_row3_col2 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_354ad_row3_col0 {\n",
       "  background-color: #97b8ff;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_354ad_row3_col1 {\n",
       "  background-color: #f7ba9f;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_354ad\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_354ad_level0_col0\" class=\"col_heading level0 col0\" >calculated_host_listings_count</th>\n",
       "      <th id=\"T_354ad_level0_col1\" class=\"col_heading level0 col1\" >LOG_PRICE</th>\n",
       "      <th id=\"T_354ad_level0_col2\" class=\"col_heading level0 col2\" >distance_to_center</th>\n",
       "      <th id=\"T_354ad_level0_col3\" class=\"col_heading level0 col3\" >encoded_neighbourhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_354ad_level0_row0\" class=\"row_heading level0 row0\" >calculated_host_listings_count</th>\n",
       "      <td id=\"T_354ad_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
       "      <td id=\"T_354ad_row0_col1\" class=\"data row0 col1\" >0.134</td>\n",
       "      <td id=\"T_354ad_row0_col2\" class=\"data row0 col2\" >-0.123</td>\n",
       "      <td id=\"T_354ad_row0_col3\" class=\"data row0 col3\" >0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_354ad_level0_row1\" class=\"row_heading level0 row1\" >LOG_PRICE</th>\n",
       "      <td id=\"T_354ad_row1_col0\" class=\"data row1 col0\" >0.134</td>\n",
       "      <td id=\"T_354ad_row1_col1\" class=\"data row1 col1\" >1.000</td>\n",
       "      <td id=\"T_354ad_row1_col2\" class=\"data row1 col2\" >-0.373</td>\n",
       "      <td id=\"T_354ad_row1_col3\" class=\"data row1 col3\" >0.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_354ad_level0_row2\" class=\"row_heading level0 row2\" >distance_to_center</th>\n",
       "      <td id=\"T_354ad_row2_col0\" class=\"data row2 col0\" >-0.123</td>\n",
       "      <td id=\"T_354ad_row2_col1\" class=\"data row2 col1\" >-0.373</td>\n",
       "      <td id=\"T_354ad_row2_col2\" class=\"data row2 col2\" >1.000</td>\n",
       "      <td id=\"T_354ad_row2_col3\" class=\"data row2 col3\" >-0.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_354ad_level0_row3\" class=\"row_heading level0 row3\" >encoded_neighbourhood</th>\n",
       "      <td id=\"T_354ad_row3_col0\" class=\"data row3 col0\" >0.192</td>\n",
       "      <td id=\"T_354ad_row3_col1\" class=\"data row3 col1\" >0.533</td>\n",
       "      <td id=\"T_354ad_row3_col2\" class=\"data row3 col2\" >-0.676</td>\n",
       "      <td id=\"T_354ad_row3_col3\" class=\"data row3 col3\" >1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5faf88ca30>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observamos el mapa de correlaciones\n",
    "# Filtramos por variables numericas\n",
    "columns_for_corr = ['calculated_host_listings_count',\t'LOG_PRICE','distance_to_center', 'encoded_neighbourhood'] \n",
    "df_for_corr = df[columns_for_corr] \n",
    "# Mapa de correlacion\n",
    "corr = df_for_corr.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>LOG_PRICE</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>coords_cluster</th>\n",
       "      <th>encoded_neighbourhood</th>\n",
       "      <th>neighbourhood_group_Bronx</th>\n",
       "      <th>neighbourhood_group_Brooklyn</th>\n",
       "      <th>neighbourhood_group_Manhattan</th>\n",
       "      <th>neighbourhood_group_Queens</th>\n",
       "      <th>neighbourhood_group_Staten Island</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>Private room</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46719</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46720</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bushwick</td>\n",
       "      <td>Private room</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46721</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.74</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46722</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>Shared room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46723</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>Private room</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46724 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neighbourhood_group       neighbourhood        room_type  \\\n",
       "0                Brooklyn          Kensington     Private room   \n",
       "1               Manhattan             Midtown  Entire home/apt   \n",
       "2               Manhattan              Harlem     Private room   \n",
       "3                Brooklyn        Clinton Hill  Entire home/apt   \n",
       "4               Manhattan         East Harlem  Entire home/apt   \n",
       "...                   ...                 ...              ...   \n",
       "46719            Brooklyn  Bedford-Stuyvesant     Private room   \n",
       "46720            Brooklyn            Bushwick     Private room   \n",
       "46721           Manhattan              Harlem  Entire home/apt   \n",
       "46722           Manhattan      Hell's Kitchen      Shared room   \n",
       "46723           Manhattan      Hell's Kitchen     Private room   \n",
       "\n",
       "       minimum_nights  number_of_reviews  calculated_host_listings_count  \\\n",
       "0                   1                  9                               6   \n",
       "1                   1                 45                               2   \n",
       "2                   3                  0                               1   \n",
       "3                   1                270                               1   \n",
       "4                  10                  9                               1   \n",
       "...               ...                ...                             ...   \n",
       "46719               2                  0                               2   \n",
       "46720               4                  0                               2   \n",
       "46721              10                  0                               1   \n",
       "46722               1                  0                               6   \n",
       "46723               7                  0                               1   \n",
       "\n",
       "       availability_365  LOG_PRICE  distance_to_center  coords_cluster  \\\n",
       "0                   365       5.00                0.07              10   \n",
       "1                   355       5.42                0.05               0   \n",
       "2                   365       5.01                0.11               3   \n",
       "3                   194       4.49                0.05               1   \n",
       "4                     0       4.38                0.10              11   \n",
       "...                 ...        ...                 ...             ...   \n",
       "46719                 9       4.25                0.07               1   \n",
       "46720                36       3.69                0.07               7   \n",
       "46721                27       4.74                0.12               3   \n",
       "46722                 2       4.01                0.05               0   \n",
       "46723                23       4.50                0.05               0   \n",
       "\n",
       "       encoded_neighbourhood  neighbourhood_group_Bronx  \\\n",
       "0                       4.34                       0.00   \n",
       "1                       5.38                       0.00   \n",
       "2                       4.56                       0.00   \n",
       "3                       4.77                       0.00   \n",
       "4                       4.63                       0.00   \n",
       "...                      ...                        ...   \n",
       "46719                   4.44                       0.00   \n",
       "46720                   4.26                       0.00   \n",
       "46721                   4.56                       0.00   \n",
       "46722                   5.12                       0.00   \n",
       "46723                   5.12                       0.00   \n",
       "\n",
       "       neighbourhood_group_Brooklyn  neighbourhood_group_Manhattan  \\\n",
       "0                              1.00                           0.00   \n",
       "1                              0.00                           1.00   \n",
       "2                              0.00                           1.00   \n",
       "3                              1.00                           0.00   \n",
       "4                              0.00                           1.00   \n",
       "...                             ...                            ...   \n",
       "46719                          1.00                           0.00   \n",
       "46720                          1.00                           0.00   \n",
       "46721                          0.00                           1.00   \n",
       "46722                          0.00                           1.00   \n",
       "46723                          0.00                           1.00   \n",
       "\n",
       "       neighbourhood_group_Queens  neighbourhood_group_Staten Island  \n",
       "0                            0.00                               0.00  \n",
       "1                            0.00                               0.00  \n",
       "2                            0.00                               0.00  \n",
       "3                            0.00                               0.00  \n",
       "4                            0.00                               0.00  \n",
       "...                           ...                                ...  \n",
       "46719                        0.00                               0.00  \n",
       "46720                        0.00                               0.00  \n",
       "46721                        0.00                               0.00  \n",
       "46722                        0.00                               0.00  \n",
       "46723                        0.00                               0.00  \n",
       "\n",
       "[46724 rows x 16 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La variable categorica neighbourhood_group solo tiene 4 valores asi que opto por one_hot\n",
    "# Instanciamos el metodo\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "# Filtramos la columna\n",
    "neighbourhoods = df[['neighbourhood_group']]\n",
    "# Ejecutamos el metodo\n",
    "encoded = encoder.fit_transform(neighbourhoods)\n",
    "# Convertimos el resultado en un dataframe, tomando los nombres de columnas de la columna original\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['neighbourhood_group']))\n",
    "# igualamos los indices entre el nuevo dataframe y el original\n",
    "encoded_df.index = df.index\n",
    "# Unimos los dos dataframes\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>room_type</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>LOG_PRICE</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>coords_cluster</th>\n",
       "      <th>encoded_neighbourhood</th>\n",
       "      <th>neighbourhood_group_Bronx</th>\n",
       "      <th>neighbourhood_group_Brooklyn</th>\n",
       "      <th>neighbourhood_group_Manhattan</th>\n",
       "      <th>neighbourhood_group_Queens</th>\n",
       "      <th>neighbourhood_group_Staten Island</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>Private room</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "      <td>5.42</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>Private room</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.11</td>\n",
       "      <td>3</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "      <td>4.49</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1</td>\n",
       "      <td>4.77</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.38</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11</td>\n",
       "      <td>4.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46719</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bedford-Stuyvesant</td>\n",
       "      <td>Private room</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4.25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46720</th>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Bushwick</td>\n",
       "      <td>Private room</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>3.69</td>\n",
       "      <td>0.07</td>\n",
       "      <td>7</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46721</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>4.74</td>\n",
       "      <td>0.12</td>\n",
       "      <td>3</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46722</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>Shared room</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46723</th>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Hell's Kitchen</td>\n",
       "      <td>Private room</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4.50</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0</td>\n",
       "      <td>5.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46724 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      neighbourhood_group       neighbourhood        room_type  \\\n",
       "0                Brooklyn          Kensington     Private room   \n",
       "1               Manhattan             Midtown  Entire home/apt   \n",
       "2               Manhattan              Harlem     Private room   \n",
       "3                Brooklyn        Clinton Hill  Entire home/apt   \n",
       "4               Manhattan         East Harlem  Entire home/apt   \n",
       "...                   ...                 ...              ...   \n",
       "46719            Brooklyn  Bedford-Stuyvesant     Private room   \n",
       "46720            Brooklyn            Bushwick     Private room   \n",
       "46721           Manhattan              Harlem  Entire home/apt   \n",
       "46722           Manhattan      Hell's Kitchen      Shared room   \n",
       "46723           Manhattan      Hell's Kitchen     Private room   \n",
       "\n",
       "       minimum_nights  number_of_reviews  calculated_host_listings_count  \\\n",
       "0                   1                  9                               6   \n",
       "1                   1                 45                               2   \n",
       "2                   3                  0                               1   \n",
       "3                   1                270                               1   \n",
       "4                  10                  9                               1   \n",
       "...               ...                ...                             ...   \n",
       "46719               2                  0                               2   \n",
       "46720               4                  0                               2   \n",
       "46721              10                  0                               1   \n",
       "46722               1                  0                               6   \n",
       "46723               7                  0                               1   \n",
       "\n",
       "       availability_365  LOG_PRICE  distance_to_center  coords_cluster  \\\n",
       "0                   365       5.00                0.07              10   \n",
       "1                   355       5.42                0.05               0   \n",
       "2                   365       5.01                0.11               3   \n",
       "3                   194       4.49                0.05               1   \n",
       "4                     0       4.38                0.10              11   \n",
       "...                 ...        ...                 ...             ...   \n",
       "46719                 9       4.25                0.07               1   \n",
       "46720                36       3.69                0.07               7   \n",
       "46721                27       4.74                0.12               3   \n",
       "46722                 2       4.01                0.05               0   \n",
       "46723                23       4.50                0.05               0   \n",
       "\n",
       "       encoded_neighbourhood  neighbourhood_group_Bronx  \\\n",
       "0                       4.34                       0.00   \n",
       "1                       5.38                       0.00   \n",
       "2                       4.56                       0.00   \n",
       "3                       4.77                       0.00   \n",
       "4                       4.63                       0.00   \n",
       "...                      ...                        ...   \n",
       "46719                   4.44                       0.00   \n",
       "46720                   4.26                       0.00   \n",
       "46721                   4.56                       0.00   \n",
       "46722                   5.12                       0.00   \n",
       "46723                   5.12                       0.00   \n",
       "\n",
       "       neighbourhood_group_Brooklyn  neighbourhood_group_Manhattan  \\\n",
       "0                              1.00                           0.00   \n",
       "1                              0.00                           1.00   \n",
       "2                              0.00                           1.00   \n",
       "3                              1.00                           0.00   \n",
       "4                              0.00                           1.00   \n",
       "...                             ...                            ...   \n",
       "46719                          1.00                           0.00   \n",
       "46720                          1.00                           0.00   \n",
       "46721                          0.00                           1.00   \n",
       "46722                          0.00                           1.00   \n",
       "46723                          0.00                           1.00   \n",
       "\n",
       "       neighbourhood_group_Queens  neighbourhood_group_Staten Island  \\\n",
       "0                            0.00                               0.00   \n",
       "1                            0.00                               0.00   \n",
       "2                            0.00                               0.00   \n",
       "3                            0.00                               0.00   \n",
       "4                            0.00                               0.00   \n",
       "...                           ...                                ...   \n",
       "46719                        0.00                               0.00   \n",
       "46720                        0.00                               0.00   \n",
       "46721                        0.00                               0.00   \n",
       "46722                        0.00                               0.00   \n",
       "46723                        0.00                               0.00   \n",
       "\n",
       "       room_type_Entire home/apt  room_type_Private room  \\\n",
       "0                           0.00                    1.00   \n",
       "1                           1.00                    0.00   \n",
       "2                           0.00                    1.00   \n",
       "3                           1.00                    0.00   \n",
       "4                           1.00                    0.00   \n",
       "...                          ...                     ...   \n",
       "46719                       0.00                    1.00   \n",
       "46720                       0.00                    1.00   \n",
       "46721                       1.00                    0.00   \n",
       "46722                       0.00                    0.00   \n",
       "46723                       0.00                    1.00   \n",
       "\n",
       "       room_type_Shared room  \n",
       "0                       0.00  \n",
       "1                       0.00  \n",
       "2                       0.00  \n",
       "3                       0.00  \n",
       "4                       0.00  \n",
       "...                      ...  \n",
       "46719                   0.00  \n",
       "46720                   0.00  \n",
       "46721                   0.00  \n",
       "46722                   1.00  \n",
       "46723                   0.00  \n",
       "\n",
       "[46724 rows x 19 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mismo proceso con 'room_type'\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "room_types = df[['room_type']]\n",
    "encoded = encoder.fit_transform(room_types)\n",
    "encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(['room_type']))\n",
    "encoded_df.index = df.index\n",
    "df = pd.concat([df, encoded_df], axis=1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora creamos el dataframe final para el modelo eliminando las columnas categoricas ya codificadas y conservando el anterior para tener una referencia de la relacion entre las columnas y facilitar el posible ajuste del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_for_model = df.drop(['neighbourhood_group','neighbourhood','room_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "      <th>LOG_PRICE</th>\n",
       "      <th>distance_to_center</th>\n",
       "      <th>coords_cluster</th>\n",
       "      <th>encoded_neighbourhood</th>\n",
       "      <th>neighbourhood_group_Bronx</th>\n",
       "      <th>neighbourhood_group_Brooklyn</th>\n",
       "      <th>neighbourhood_group_Manhattan</th>\n",
       "      <th>neighbourhood_group_Queens</th>\n",
       "      <th>neighbourhood_group_Staten Island</th>\n",
       "      <th>room_type_Entire home/apt</th>\n",
       "      <th>room_type_Private room</th>\n",
       "      <th>room_type_Shared room</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>10</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   minimum_nights  number_of_reviews  calculated_host_listings_count  \\\n",
       "0               1                  9                               6   \n",
       "\n",
       "   availability_365  LOG_PRICE  distance_to_center  coords_cluster  \\\n",
       "0               365       5.00                0.07              10   \n",
       "\n",
       "   encoded_neighbourhood  neighbourhood_group_Bronx  \\\n",
       "0                   4.34                       0.00   \n",
       "\n",
       "   neighbourhood_group_Brooklyn  neighbourhood_group_Manhattan  \\\n",
       "0                          1.00                           0.00   \n",
       "\n",
       "   neighbourhood_group_Queens  neighbourhood_group_Staten Island  \\\n",
       "0                        0.00                               0.00   \n",
       "\n",
       "   room_type_Entire home/apt  room_type_Private room  room_type_Shared room  \n",
       "0                       0.00                    1.00                   0.00  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for_model.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habiendo definido las columnas de interes, limpiado y codificado el dataframe original, procedemos con el preprocesamiento de los datos para el modelo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diferenciamos columnas cuantitativas de las categoricas codificadas\n",
    "cuantitative_columns = ['calculated_host_listings_count','LOG_PRICE','distance_to_center','encoded_neighbourhood']\n",
    "df_cuantitative = df_for_model[cuantitative_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculated_host_listings_count   8.20\n",
       "LOG_PRICE                        0.47\n",
       "distance_to_center               1.27\n",
       "encoded_neighbourhood            0.25\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculamos la asimetria\n",
    "df_cuantitative.apply(lambda x: x.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos el metodo de windsorizacion (muy suave) para reducir skewness\n",
    "def winsorize_column(column, lower, upper):\n",
    "    q1 = column.quantile(lower)\n",
    "    q3 = column.quantile(upper)\n",
    "    iqr_value = q3-q1\n",
    "    lower_bound = q1 - 1.5 * iqr_value\n",
    "    upper_bound = q3 + 1.5 * iqr_value\n",
    "    column = column.clip(lower=lower_bound, upper=upper_bound)\n",
    "    return column\n",
    "\n",
    "# Aplicamos winsorización a cada columna del dataframe\n",
    "for column in df_cuantitative.columns:\n",
    "    df_cuantitative[column] = winsorize_column(df_cuantitative[column], 0.05, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "calculated_host_listings_count   1.18\n",
       "LOG_PRICE                        0.39\n",
       "distance_to_center               1.06\n",
       "encoded_neighbourhood            0.25\n",
       "dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Una vez aplicada la Windsorizacion recalculamos la asimetria\n",
    "df_cuantitative.apply(lambda x: x.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_66d2f_row0_col0, #T_66d2f_row1_col1, #T_66d2f_row2_col2, #T_66d2f_row3_col3 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66d2f_row0_col1 {\n",
       "  background-color: #7ea1fa;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66d2f_row0_col2 {\n",
       "  background-color: #d3dbe7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66d2f_row0_col3 {\n",
       "  background-color: #bcd2f7;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66d2f_row1_col0, #T_66d2f_row2_col1, #T_66d2f_row2_col3, #T_66d2f_row3_col2 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66d2f_row1_col2 {\n",
       "  background-color: #7597f6;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66d2f_row1_col3 {\n",
       "  background-color: #f6a385;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_66d2f_row2_col0 {\n",
       "  background-color: #7093f3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66d2f_row3_col0 {\n",
       "  background-color: #4a63d3;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_66d2f_row3_col1 {\n",
       "  background-color: #f7b99e;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_66d2f\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_66d2f_level0_col0\" class=\"col_heading level0 col0\" >calculated_host_listings_count</th>\n",
       "      <th id=\"T_66d2f_level0_col1\" class=\"col_heading level0 col1\" >LOG_PRICE</th>\n",
       "      <th id=\"T_66d2f_level0_col2\" class=\"col_heading level0 col2\" >distance_to_center</th>\n",
       "      <th id=\"T_66d2f_level0_col3\" class=\"col_heading level0 col3\" >encoded_neighbourhood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_66d2f_level0_row0\" class=\"row_heading level0 row0\" >calculated_host_listings_count</th>\n",
       "      <td id=\"T_66d2f_row0_col0\" class=\"data row0 col0\" >1.000</td>\n",
       "      <td id=\"T_66d2f_row0_col1\" class=\"data row0 col1\" >-0.091</td>\n",
       "      <td id=\"T_66d2f_row0_col2\" class=\"data row0 col2\" >0.095</td>\n",
       "      <td id=\"T_66d2f_row0_col3\" class=\"data row0 col3\" >-0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66d2f_level0_row1\" class=\"row_heading level0 row1\" >LOG_PRICE</th>\n",
       "      <td id=\"T_66d2f_row1_col0\" class=\"data row1 col0\" >-0.091</td>\n",
       "      <td id=\"T_66d2f_row1_col1\" class=\"data row1 col1\" >1.000</td>\n",
       "      <td id=\"T_66d2f_row1_col2\" class=\"data row1 col2\" >-0.382</td>\n",
       "      <td id=\"T_66d2f_row1_col3\" class=\"data row1 col3\" >0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66d2f_level0_row2\" class=\"row_heading level0 row2\" >distance_to_center</th>\n",
       "      <td id=\"T_66d2f_row2_col0\" class=\"data row2 col0\" >0.095</td>\n",
       "      <td id=\"T_66d2f_row2_col1\" class=\"data row2 col1\" >-0.382</td>\n",
       "      <td id=\"T_66d2f_row2_col2\" class=\"data row2 col2\" >1.000</td>\n",
       "      <td id=\"T_66d2f_row2_col3\" class=\"data row2 col3\" >-0.689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_66d2f_level0_row3\" class=\"row_heading level0 row3\" >encoded_neighbourhood</th>\n",
       "      <td id=\"T_66d2f_row3_col0\" class=\"data row3 col0\" >-0.032</td>\n",
       "      <td id=\"T_66d2f_row3_col1\" class=\"data row3 col1\" >0.535</td>\n",
       "      <td id=\"T_66d2f_row3_col2\" class=\"data row3 col2\" >-0.689</td>\n",
       "      <td id=\"T_66d2f_row3_col3\" class=\"data row3 col3\" >1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5faf8d5cc0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De nuevo mapa de correlacion // despues del ajuste las correlaciones son mas claras\n",
    "corr = df_cuantitative.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').format(precision=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable dependiente e independiente\n",
    "X = df_for_model.drop(['LOG_PRICE'], axis=1)\n",
    "y = df_for_model['LOG_PRICE']\n",
    "\n",
    "# Dividimos los datos para el modelo\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividimos los datos en cuantitativos y binarios para el escalado y posterior concatenacion\n",
    "\n",
    "# Definimos columnas numericas\n",
    "num_cols = ['calculated_host_listings_count','distance_to_center',\t'encoded_neighbourhood']\n",
    "# Creamos dos conjuntos de datos independientes binarios/cuantitativos\n",
    "\n",
    "X_train_bin = X_train.drop(num_cols, axis=1)\n",
    "X_test_bin = X_test.drop(num_cols, axis=1)\n",
    "\n",
    "X_train_num = X_train[num_cols]\n",
    "X_test_num = X_test[num_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una instancia al metodo de escalado\n",
    "scaler = MinMaxScaler().fit(X_train_num)\n",
    "\n",
    "# Escalamos solo los valores cuantitativos\n",
    "X_train_sc = scaler.transform(X_train_num)\n",
    "X_test_sc = scaler.transform(X_test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unimos los datos cuantitativos con los binarios\n",
    "X_train_final = pd.concat([X_train_num, X_train_bin], axis=1)\n",
    "X_test_final = pd.concat([X_test_num, X_test_bin], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 41/42 [03:51<00:09,  9.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001989 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1065\n",
      "[LightGBM] [Info] Number of data points in the train set: 37379, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42/42 [03:51<00:00,  5.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# Buscamos el modelo que mejor desempeño tenga\n",
    "from lazypredict.Supervised import LazyRegressor\n",
    "reg = LazyRegressor()\n",
    "# aplicamos \n",
    "models, predictions = reg.fit(X_train_final, X_test_final, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               Adjusted R-Squared  R-Squared  RMSE  Time Taken\n",
      "Model                                                                         \n",
      "LGBMRegressor                                0.61       0.61  0.42        0.35\n",
      "HistGradientBoostingRegressor                0.61       0.61  0.42        0.70\n",
      "XGBRegressor                                 0.60       0.61  0.42        0.42\n",
      "GradientBoostingRegressor                    0.59       0.59  0.43        4.39\n",
      "RandomForestRegressor                        0.59       0.59  0.43       15.13\n",
      "NuSVR                                        0.58       0.58  0.43       81.19\n",
      "SVR                                          0.58       0.58  0.44       60.10\n",
      "MLPRegressor                                 0.58       0.58  0.44        9.70\n",
      "ExtraTreesRegressor                          0.56       0.56  0.44        7.45\n",
      "BaggingRegressor                             0.55       0.55  0.45        1.96\n",
      "TransformedTargetRegressor                   0.54       0.54  0.45        0.03\n",
      "LinearRegression                             0.54       0.54  0.45        0.06\n",
      "BayesianRidge                                0.54       0.54  0.45        0.06\n",
      "RidgeCV                                      0.54       0.54  0.45        0.06\n",
      "Ridge                                        0.54       0.54  0.45        0.02\n",
      "Lars                                         0.54       0.54  0.45        0.03\n",
      "LassoLarsIC                                  0.54       0.54  0.45        0.06\n",
      "LassoLarsCV                                  0.54       0.54  0.45        0.10\n",
      "LarsCV                                       0.54       0.54  0.45        0.13\n",
      "ElasticNetCV                                 0.54       0.54  0.45        0.34\n",
      "LassoCV                                      0.54       0.54  0.45        0.67\n",
      "SGDRegressor                                 0.54       0.54  0.46        0.09\n",
      "OrthogonalMatchingPursuitCV                  0.53       0.54  0.46        0.07\n",
      "HuberRegressor                               0.53       0.54  0.46        0.13\n",
      "PoissonRegressor                             0.53       0.53  0.46        0.03\n",
      "LinearSVR                                    0.53       0.53  0.46        2.48\n",
      "KNeighborsRegressor                          0.53       0.53  0.46        3.01\n",
      "TweedieRegressor                             0.49       0.49  0.48        0.03\n",
      "GammaRegressor                               0.48       0.49  0.48        0.03\n",
      "RANSACRegressor                              0.39       0.39  0.52        0.18\n",
      "OrthogonalMatchingPursuit                    0.38       0.38  0.53        0.02\n",
      "AdaBoostRegressor                            0.37       0.37  0.53        1.84\n",
      "DecisionTreeRegressor                        0.24       0.25  0.58        0.26\n",
      "ExtraTreeRegressor                           0.23       0.23  0.59        0.12\n",
      "LassoLars                                   -0.00      -0.00  0.67        0.03\n",
      "Lasso                                       -0.00      -0.00  0.67        0.03\n",
      "ElasticNet                                  -0.00      -0.00  0.67        0.02\n",
      "DummyRegressor                              -0.00      -0.00  0.67        0.02\n",
      "QuantileRegressor                           -0.01      -0.01  0.67       40.15\n",
      "PassiveAggressiveRegressor                  -0.07      -0.06  0.69        0.05\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos los resultados \n",
    "print(models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=240, n_estimators=20, num_leaves=50; total time=   0.2s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=240, n_estimators=20, num_leaves=50; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=240, n_estimators=20, num_leaves=50; total time=   0.1s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=240, n_estimators=20, num_leaves=50; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=240, n_estimators=20, num_leaves=50; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=230, n_estimators=180, num_leaves=140; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=230, n_estimators=180, num_leaves=140; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=230, n_estimators=180, num_leaves=140; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=230, n_estimators=180, num_leaves=140; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=70, num_leaves=160; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=70, num_leaves=160; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=230, n_estimators=180, num_leaves=140; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=70, num_leaves=160; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=70, num_leaves=160; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=70, num_leaves=160; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.1778279410038923, max_depth=240, n_estimators=40, num_leaves=150; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.1778279410038923, max_depth=240, n_estimators=40, num_leaves=150; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.1778279410038923, max_depth=240, n_estimators=40, num_leaves=150; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.1778279410038923, max_depth=240, n_estimators=40, num_leaves=150; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=20, n_estimators=20, num_leaves=210; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.1778279410038923, max_depth=240, n_estimators=40, num_leaves=150; total time=   0.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=20, n_estimators=20, num_leaves=210; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=20, n_estimators=20, num_leaves=210; total time=   0.2s\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=20, n_estimators=20, num_leaves=210; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=20, n_estimators=20, num_leaves=210; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=110, n_estimators=80, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=110, n_estimators=80, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=110, n_estimators=80, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=110, n_estimators=80, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=110, n_estimators=80, num_leaves=80; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=80, n_estimators=210, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=80, n_estimators=210, num_leaves=10; total time=   4.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=80, n_estimators=210, num_leaves=10; total time=   4.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=80, n_estimators=210, num_leaves=10; total time=   4.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=80, n_estimators=210, num_leaves=10; total time=   3.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=30, n_estimators=160, num_leaves=220; total time=   7.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=30, n_estimators=160, num_leaves=220; total time=   7.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=30, n_estimators=160, num_leaves=220; total time=   7.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=30, n_estimators=160, num_leaves=220; total time=   8.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=20, num_leaves=30; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=20, num_leaves=30; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=20, num_leaves=30; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=20, num_leaves=30; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=20, num_leaves=30; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=120, n_estimators=130, num_leaves=120; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=120, n_estimators=130, num_leaves=120; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=120, n_estimators=130, num_leaves=120; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=30, n_estimators=160, num_leaves=220; total time=   8.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=120, n_estimators=130, num_leaves=120; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=180, num_leaves=190; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=180, num_leaves=190; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=180, num_leaves=190; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=180, num_leaves=190; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=180, num_leaves=190; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=120, n_estimators=130, num_leaves=120; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=140, num_leaves=120; total time=   4.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=140, num_leaves=120; total time=   4.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=140, num_leaves=120; total time=   4.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=140, num_leaves=120; total time=   4.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=10, num_leaves=20; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=10, num_leaves=20; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=10, num_leaves=20; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=10, num_leaves=20; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=10, num_leaves=20; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=100, n_estimators=80, num_leaves=120; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=100, n_estimators=80, num_leaves=120; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=100, n_estimators=80, num_leaves=120; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=100, n_estimators=80, num_leaves=120; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=100, n_estimators=80, num_leaves=120; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=120, n_estimators=140, num_leaves=120; total time=   4.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=220, num_leaves=100; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=220, num_leaves=100; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=220, num_leaves=100; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=220, num_leaves=100; total time=   2.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.001, max_depth=190, n_estimators=30, num_leaves=140; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.001, max_depth=190, n_estimators=30, num_leaves=140; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.001, max_depth=190, n_estimators=30, num_leaves=140; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.001, max_depth=190, n_estimators=30, num_leaves=140; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.001, max_depth=190, n_estimators=30, num_leaves=140; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=220, num_leaves=100; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=70, n_estimators=170, num_leaves=100; total time=   6.0s\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=70, n_estimators=170, num_leaves=100; total time=   6.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=70, n_estimators=170, num_leaves=100; total time=   6.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=70, n_estimators=170, num_leaves=100; total time=   6.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=90, num_leaves=10; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=90, num_leaves=10; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=90, num_leaves=10; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=90, num_leaves=10; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=60, n_estimators=90, num_leaves=10; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=210, num_leaves=120; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=210, num_leaves=120; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=210, num_leaves=120; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=210, num_leaves=120; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=210, num_leaves=120; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=20, n_estimators=140, num_leaves=90; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=20, n_estimators=140, num_leaves=90; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=20, n_estimators=140, num_leaves=90; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=20, n_estimators=140, num_leaves=90; total time=   0.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=20, n_estimators=140, num_leaves=90; total time=   1.1s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=130, n_estimators=0, num_leaves=230; total time=   0.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=130, n_estimators=0, num_leaves=230; total time=   0.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=130, n_estimators=0, num_leaves=230; total time=   0.0s\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=70, n_estimators=170, num_leaves=100; total time=   6.1s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=130, n_estimators=0, num_leaves=230; total time=   0.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=130, n_estimators=0, num_leaves=230; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=80, n_estimators=130, num_leaves=150; total time=   1.1s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=80, n_estimators=130, num_leaves=150; total time=   1.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=80, n_estimators=130, num_leaves=150; total time=   1.1s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=80, n_estimators=130, num_leaves=150; total time=   1.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=80, n_estimators=130, num_leaves=150; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=140, n_estimators=120, num_leaves=190; total time=   4.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=140, n_estimators=120, num_leaves=190; total time=   4.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=140, n_estimators=120, num_leaves=190; total time=   4.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=140, n_estimators=120, num_leaves=190; total time=   4.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=90, num_leaves=220; total time=   2.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=140, n_estimators=120, num_leaves=190; total time=   4.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=90, num_leaves=220; total time=   2.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=90, num_leaves=220; total time=   2.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=90, num_leaves=220; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=230, n_estimators=90, num_leaves=60; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=90, num_leaves=220; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=230, n_estimators=90, num_leaves=60; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=230, n_estimators=90, num_leaves=60; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=230, n_estimators=90, num_leaves=60; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=30, num_leaves=160; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=30, num_leaves=160; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=30, num_leaves=160; total time=   0.1s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.005623413251903491, max_depth=230, n_estimators=90, num_leaves=60; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=30, num_leaves=160; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=30, num_leaves=160; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=110, n_estimators=50, num_leaves=150; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=110, n_estimators=50, num_leaves=150; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=110, n_estimators=50, num_leaves=150; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=110, n_estimators=50, num_leaves=150; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=110, n_estimators=50, num_leaves=150; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=190, n_estimators=10, num_leaves=50; total time=   0.1s\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=190, n_estimators=10, num_leaves=50; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=190, n_estimators=10, num_leaves=50; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=190, n_estimators=10, num_leaves=50; total time=   0.2s\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=190, n_estimators=10, num_leaves=50; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=30, n_estimators=190, num_leaves=80; total time=   6.6s\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=30, n_estimators=190, num_leaves=80; total time=   6.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=30, n_estimators=190, num_leaves=80; total time=   6.7s\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=30, n_estimators=190, num_leaves=80; total time=   6.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=240, num_leaves=80; total time=   0.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=240, num_leaves=80; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=240, num_leaves=80; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=240, num_leaves=80; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=240, num_leaves=80; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=110, n_estimators=160, num_leaves=100; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=110, n_estimators=160, num_leaves=100; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=110, n_estimators=160, num_leaves=100; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=110, n_estimators=160, num_leaves=100; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=110, n_estimators=160, num_leaves=100; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=230, num_leaves=50; total time=   0.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.001, max_depth=30, n_estimators=190, num_leaves=80; total time=   7.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=230, num_leaves=50; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=230, num_leaves=50; total time=   0.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=230, num_leaves=50; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=50, num_leaves=230; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=50, num_leaves=230; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=50, num_leaves=230; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=50, num_leaves=230; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=1.0, max_depth=40, n_estimators=50, num_leaves=230; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=20, num_leaves=160; total time=   0.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=60, n_estimators=230, num_leaves=50; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=20, num_leaves=160; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=20, num_leaves=160; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=20, num_leaves=160; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.03162277660168379, max_depth=200, n_estimators=20, num_leaves=160; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=220, n_estimators=150, num_leaves=80; total time=   4.5s\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=220, n_estimators=150, num_leaves=80; total time=   4.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=220, n_estimators=150, num_leaves=80; total time=   4.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=220, n_estimators=150, num_leaves=80; total time=   4.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.005623413251903491, max_depth=230, n_estimators=120, num_leaves=240; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.005623413251903491, max_depth=230, n_estimators=120, num_leaves=240; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.005623413251903491, max_depth=230, n_estimators=120, num_leaves=240; total time=   0.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.005623413251903491, max_depth=230, n_estimators=120, num_leaves=240; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.005623413251903491, max_depth=230, n_estimators=120, num_leaves=240; total time=   0.1s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=190, n_estimators=0, num_leaves=160; total time=   0.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=190, n_estimators=0, num_leaves=160; total time=   0.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=190, n_estimators=0, num_leaves=160; total time=   0.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=190, n_estimators=0, num_leaves=160; total time=   0.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=190, n_estimators=0, num_leaves=160; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=130, num_leaves=130; total time=   3.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=220, n_estimators=150, num_leaves=80; total time=   4.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=130, num_leaves=130; total time=   2.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=130, num_leaves=130; total time=   3.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=130, num_leaves=130; total time=   3.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=80, n_estimators=50, num_leaves=30; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=80, n_estimators=50, num_leaves=30; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=80, n_estimators=50, num_leaves=30; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=80, n_estimators=50, num_leaves=30; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.1778279410038923, max_depth=80, n_estimators=50, num_leaves=30; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=50, n_estimators=30, num_leaves=40; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=50, n_estimators=30, num_leaves=40; total time=   0.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=1.0, max_depth=230, n_estimators=130, num_leaves=130; total time=   3.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=50, n_estimators=30, num_leaves=40; total time=   0.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=50, n_estimators=30, num_leaves=40; total time=   0.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.001, max_depth=50, n_estimators=30, num_leaves=40; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=180, n_estimators=100, num_leaves=70; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=180, n_estimators=100, num_leaves=70; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=180, n_estimators=100, num_leaves=70; total time=   0.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=180, n_estimators=100, num_leaves=70; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=180, n_estimators=100, num_leaves=70; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=150, n_estimators=130, num_leaves=130; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=150, n_estimators=130, num_leaves=130; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=150, n_estimators=130, num_leaves=130; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=150, n_estimators=130, num_leaves=130; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=150, n_estimators=130, num_leaves=130; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=180, n_estimators=40, num_leaves=190; total time=   0.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=180, n_estimators=40, num_leaves=190; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=180, n_estimators=40, num_leaves=190; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=180, n_estimators=40, num_leaves=190; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=180, n_estimators=40, num_leaves=190; total time=   0.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=140, n_estimators=210, num_leaves=170; total time=  10.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=140, n_estimators=210, num_leaves=170; total time=  10.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=140, n_estimators=210, num_leaves=170; total time=  10.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=140, n_estimators=210, num_leaves=170; total time=  10.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=80, n_estimators=160, num_leaves=200; total time=   7.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=140, n_estimators=210, num_leaves=170; total time=  10.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=80, n_estimators=160, num_leaves=200; total time=   7.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=80, n_estimators=160, num_leaves=200; total time=   7.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=80, n_estimators=160, num_leaves=200; total time=   7.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=70, n_estimators=40, num_leaves=160; total time=   0.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=70, n_estimators=40, num_leaves=160; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=70, n_estimators=40, num_leaves=160; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=70, n_estimators=40, num_leaves=160; total time=   0.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.1778279410038923, max_depth=70, n_estimators=40, num_leaves=160; total time=   0.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=80, n_estimators=160, num_leaves=200; total time=   7.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=200, n_estimators=200, num_leaves=110; total time=   8.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=200, n_estimators=200, num_leaves=110; total time=   7.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=200, n_estimators=200, num_leaves=110; total time=   8.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=200, n_estimators=200, num_leaves=110; total time=   8.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=40, num_leaves=190; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=40, num_leaves=190; total time=   0.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=40, num_leaves=190; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=40, num_leaves=190; total time=   0.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=1.0, max_depth=210, n_estimators=40, num_leaves=190; total time=   0.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=150, n_estimators=110, num_leaves=20; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=150, n_estimators=110, num_leaves=20; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=150, n_estimators=110, num_leaves=20; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=dart, learning_rate=0.005623413251903491, max_depth=200, n_estimators=200, num_leaves=110; total time=   8.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=150, n_estimators=110, num_leaves=20; total time=   1.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=220, num_leaves=80; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=220, num_leaves=80; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=220, num_leaves=80; total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n",
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=220, num_leaves=80; total time=   0.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=rf, learning_rate=0.03162277660168379, max_depth=140, n_estimators=220, num_leaves=80; total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] Check failed: (config->bagging_freq > 0 && config->bagging_fraction < 1.0f && config->bagging_fraction > 0.0f) || (config->feature_fraction < 1.0f && config->feature_fraction > 0.0f) at /__w/1/s/lightgbm-python/src/boosting/rf.hpp, line 36 .\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END boosting_type=dart, learning_rate=0.03162277660168379, max_depth=150, n_estimators=110, num_leaves=20; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Total Bins 1091\n",
      "[LightGBM] [Info] Number of data points in the train set: 37379, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(force_col_wise=True),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;, &#x27;rf&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
       "                                        &#x27;max_depth&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240]),\n",
       "                                        &#x27;n_estimators&#x27;: array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240]),\n",
       "                                        &#x27;num_leaves&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240])},\n",
       "                   random_state=52, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomizedSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=LGBMRegressor(force_col_wise=True),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;, &#x27;dart&#x27;, &#x27;rf&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
       "                                        &#x27;max_depth&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240]),\n",
       "                                        &#x27;n_estimators&#x27;: array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240]),\n",
       "                                        &#x27;num_leaves&#x27;: array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240])},\n",
       "                   random_state=52, scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "                   verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(force_col_wise=True)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor(force_col_wise=True)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=LGBMRegressor(force_col_wise=True),\n",
       "                   n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'boosting_type': ['gbdt', 'dart', 'rf'],\n",
       "                                        'learning_rate': array([0.001     , 0.00562341, 0.03162278, 0.17782794, 1.        ]),\n",
       "                                        'max_depth': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240]),\n",
       "                                        'n_estimators': array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
       "       130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240]),\n",
       "                                        'num_leaves': array([ 10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120, 130,\n",
       "       140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240])},\n",
       "                   random_state=52, scoring='neg_root_mean_squared_error',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Buscaremos un mejor ajuste del modelo LGBMRegressor ( El segundo de la lista, mismo desempeño pero algo mas rapido en ejecución)\n",
    "model = lgb.LGBMRegressor(force_col_wise=True)\n",
    "# Establecemos el rango de hiperparametros sobre los que iterará RandomizedSearchCV\n",
    "param_dict = {'boosting_type': ['gbdt','dart','rf'],\n",
    "              'num_leaves': np.arange(10, 250, 10),\n",
    "              'max_depth':np.arange(10, 250, 10),\n",
    "              'learning_rate':np.logspace(-3,0,5),\n",
    "              'n_estimators': np.arange(0, 250, 10)}\n",
    "# Creamos una instancia de RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dict, n_iter=50, cv=5, random_state=52, n_jobs=-1, scoring='neg_root_mean_squared_error', verbose=2)\n",
    "# Llamamos al metodo fit de la instancia creada que efectuara una busqueda aleatoria de la mejor combinacion de hiperparametros\n",
    "random_search.fit(X_train_final, y_train)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "{'num_leaves': 100, 'n_estimators': 220, 'max_depth': 200, 'learning_rate': 0.03162277660168379, 'boosting_type': 'gbdt'}\n",
      "Mejor puntuación (RMSE) en el conjunto de prueba:\n",
      "0.4085394192653876\n"
     ]
    }
   ],
   "source": [
    "# Mostramos los mejores hiperparámetros encontrados\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Mostramos el rendimiento del mejor modelo\n",
    "print(\"Mejor puntuación (RMSE) en el conjunto de prueba:\")\n",
    "print(-1*random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=245, n_estimators=215, num_leaves=125; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=245, n_estimators=215, num_leaves=125; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=245, n_estimators=215, num_leaves=125; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=245, n_estimators=215, num_leaves=125; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=245, n_estimators=215, num_leaves=125; total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003350 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=201, n_estimators=247, num_leaves=140; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003023 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=201, n_estimators=247, num_leaves=140; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=201, n_estimators=247, num_leaves=140; total time=   1.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000980 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=201, n_estimators=247, num_leaves=140; total time=   1.9s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=201, n_estimators=247, num_leaves=140; total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=221, num_leaves=90; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=221, num_leaves=90; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004031 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=221, num_leaves=90; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=221, num_leaves=90; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=221, num_leaves=90; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003325 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=221, n_estimators=240, num_leaves=115; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=221, n_estimators=240, num_leaves=115; total time=   2.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=221, n_estimators=240, num_leaves=115; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=221, n_estimators=240, num_leaves=115; total time=   2.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=221, n_estimators=240, num_leaves=115; total time=   1.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000902 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=235, num_leaves=140; total time=   2.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007876 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=235, num_leaves=140; total time=   2.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=235, num_leaves=140; total time=   1.8s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=235, num_leaves=140; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=235, num_leaves=140; total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012753 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=209, num_leaves=135; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=209, num_leaves=135; total time=   1.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=209, num_leaves=135; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=209, num_leaves=135; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=209, num_leaves=135; total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=205, n_estimators=243, num_leaves=120; total time=   1.8s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=205, n_estimators=243, num_leaves=120; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003348 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=205, n_estimators=243, num_leaves=120; total time=   1.8s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=205, n_estimators=243, num_leaves=120; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=205, n_estimators=243, num_leaves=120; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001275 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=214, n_estimators=241, num_leaves=100; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=214, n_estimators=241, num_leaves=100; total time=   1.7s\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021592 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003337 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=214, n_estimators=241, num_leaves=100; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=214, n_estimators=241, num_leaves=100; total time=   1.7s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=214, n_estimators=241, num_leaves=100; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000888 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=241, n_estimators=220, num_leaves=105; total time=   1.9s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=241, n_estimators=220, num_leaves=105; total time=   1.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004122 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "\n",
      "[LightGBM] [Info] Total Bins 1083[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=241, n_estimators=220, num_leaves=105; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=241, n_estimators=220, num_leaves=105; total time=   1.5s\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=241, n_estimators=220, num_leaves=105; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025517 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=212, num_leaves=120; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=212, num_leaves=120; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000938 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=212, num_leaves=120; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012924 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=212, num_leaves=120; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=212, num_leaves=120; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=196, n_estimators=219, num_leaves=90; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=196, n_estimators=219, num_leaves=90; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=196, n_estimators=219, num_leaves=90; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=196, n_estimators=219, num_leaves=90; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=196, n_estimators=219, num_leaves=90; total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=207, num_leaves=90; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=207, num_leaves=90; total time=   1.2s\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=207, num_leaves=90; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=207, num_leaves=90; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=207, num_leaves=90; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=248, num_leaves=90; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=248, num_leaves=90; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=248, num_leaves=90; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=248, num_leaves=90; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=187, n_estimators=248, num_leaves=90; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=217, n_estimators=248, num_leaves=85; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=217, n_estimators=248, num_leaves=85; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=217, n_estimators=248, num_leaves=85; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=217, n_estimators=248, num_leaves=85; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=217, n_estimators=248, num_leaves=85; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003472 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=222, num_leaves=130; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010539 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=222, num_leaves=130; total time=   1.8s\n",
      "\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004603 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=222, num_leaves=130; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=222, num_leaves=130; total time=   2.1s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=222, num_leaves=130; total time=   1.5s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.[LightGBM] [Info] Start training from score 4.715398\n",
      "\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=248, n_estimators=235, num_leaves=110; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=248, n_estimators=235, num_leaves=110; total time=   2.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003372 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=248, n_estimators=235, num_leaves=110; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=248, n_estimators=235, num_leaves=110; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=248, n_estimators=235, num_leaves=110; total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003196 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=130; total time=   1.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003498 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=130; total time=   2.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004568 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=130; total time=   2.2s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=130; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=130; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003279 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=80; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=80; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=80; total time=   1.7s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=80; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=204, n_estimators=248, num_leaves=80; total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=232, n_estimators=248, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=232, n_estimators=248, num_leaves=80; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008182 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=232, n_estimators=248, num_leaves=80; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003373 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=232, n_estimators=248, num_leaves=80; total time=   1.7s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=232, n_estimators=248, num_leaves=80; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=249, n_estimators=248, num_leaves=80; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=249, n_estimators=248, num_leaves=80; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=249, n_estimators=248, num_leaves=80; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003655 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=249, n_estimators=248, num_leaves=80; total time=   1.8s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=249, n_estimators=248, num_leaves=80; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=192, n_estimators=248, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003596 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=192, n_estimators=248, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003336 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=192, n_estimators=248, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=192, n_estimators=248, num_leaves=80; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=192, n_estimators=248, num_leaves=80; total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=226, n_estimators=249, num_leaves=95; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=226, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003508 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003225 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=226, n_estimators=249, num_leaves=95; total time=   1.9s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=226, n_estimators=249, num_leaves=95; total time=   2.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=226, n_estimators=249, num_leaves=95; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003100 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003413 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=187, n_estimators=200, num_leaves=90; total time=   1.2s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=187, n_estimators=200, num_leaves=90; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=187, n_estimators=200, num_leaves=90; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001301 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=187, n_estimators=200, num_leaves=90; total time=   1.8s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=187, n_estimators=200, num_leaves=90; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003274 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004988 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=202, num_leaves=145; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=202, num_leaves=145; total time=   1.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004822 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=202, num_leaves=145; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003865 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=202, num_leaves=145; total time=   2.0s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=202, num_leaves=145; total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=185, n_estimators=224, num_leaves=90; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=185, n_estimators=224, num_leaves=90; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=185, n_estimators=224, num_leaves=90; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=185, n_estimators=224, num_leaves=90; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=185, n_estimators=224, num_leaves=90; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=235, num_leaves=80; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=235, num_leaves=80; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003470 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=235, num_leaves=80; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003499 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=235, num_leaves=80; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=234, n_estimators=235, num_leaves=80; total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003682 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003253 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=193, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=193, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=193, n_estimators=249, num_leaves=95; total time=   1.8s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=193, n_estimators=249, num_leaves=95; total time=   1.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000966 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=193, n_estimators=249, num_leaves=95; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004019 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=226, n_estimators=242, num_leaves=90; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=226, n_estimators=242, num_leaves=90; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=226, n_estimators=242, num_leaves=90; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001391 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=226, n_estimators=242, num_leaves=90; total time=   1.7s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=226, n_estimators=242, num_leaves=90; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003358 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=201, n_estimators=243, num_leaves=80; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003932 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=201, n_estimators=243, num_leaves=80; total time=   1.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003438 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=201, n_estimators=243, num_leaves=80; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003464 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=201, n_estimators=243, num_leaves=80; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=201, n_estimators=243, num_leaves=80; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003314 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=95; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=95; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=95; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000672 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=95; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=240, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003513 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=240, num_leaves=80; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003497 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=240, num_leaves=80; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003424 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=240, num_leaves=80; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=240, num_leaves=80; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002634 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=241, num_leaves=80; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=241, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=241, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=241, num_leaves=80; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=216, n_estimators=241, num_leaves=80; total time=   1.3s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000887 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000899 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=196, n_estimators=247, num_leaves=80; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=196, n_estimators=247, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006266 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=196, n_estimators=247, num_leaves=80; total time=   1.5s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=196, n_estimators=247, num_leaves=80; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000649 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=196, n_estimators=247, num_leaves=80; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003829 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=191, n_estimators=215, num_leaves=80; total time=   1.2s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=191, n_estimators=215, num_leaves=80; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=191, n_estimators=215, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000911 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=191, n_estimators=215, num_leaves=80; total time=   1.5s\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=191, n_estimators=215, num_leaves=80; total time=   0.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003453 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004367 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=191, n_estimators=212, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000643 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.025, max_depth=191, n_estimators=212, num_leaves=80; total time=   0.9s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004906 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=213, n_estimators=249, num_leaves=95; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=213, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001008 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=213, n_estimators=249, num_leaves=95; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000882 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=213, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=213, n_estimators=249, num_leaves=95; total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003360 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=201, n_estimators=206, num_leaves=80; total time=   1.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003584 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=201, n_estimators=206, num_leaves=80; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=201, n_estimators=206, num_leaves=80; total time=   1.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004282 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=201, n_estimators=206, num_leaves=80; total time=   1.2s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=201, n_estimators=206, num_leaves=80; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000978 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006198 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=241, n_estimators=241, num_leaves=80; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=241, n_estimators=241, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=241, n_estimators=241, num_leaves=80; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003442 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=241, n_estimators=241, num_leaves=80; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=241, n_estimators=241, num_leaves=80; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003511 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003520 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=245, n_estimators=220, num_leaves=95; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003431 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=245, n_estimators=220, num_leaves=95; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003306 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=245, n_estimators=220, num_leaves=95; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003378 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=245, n_estimators=220, num_leaves=95; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=245, n_estimators=220, num_leaves=95; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000905 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=242, n_estimators=249, num_leaves=95; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=242, n_estimators=249, num_leaves=95; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003524 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=242, n_estimators=249, num_leaves=95; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=242, n_estimators=249, num_leaves=95; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=242, n_estimators=249, num_leaves=95; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=204, n_estimators=202, num_leaves=90; total time=   1.2s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=204, n_estimators=202, num_leaves=90; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003407 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000986 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=204, n_estimators=202, num_leaves=90; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=204, n_estimators=202, num_leaves=90; total time=   1.3s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=204, n_estimators=202, num_leaves=90; total time=   0.8s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=184, n_estimators=249, num_leaves=95; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=184, n_estimators=249, num_leaves=95; total time=   1.5s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009108 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=184, n_estimators=249, num_leaves=95; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000868 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=184, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=184, n_estimators=249, num_leaves=95; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003309 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=214, n_estimators=243, num_leaves=80; total time=   1.4s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=214, n_estimators=243, num_leaves=80; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=214, n_estimators=243, num_leaves=80; total time=   1.2s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003376 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=214, n_estimators=243, num_leaves=80; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=214, n_estimators=243, num_leaves=80; total time=   1.0s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=135; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=135; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003664 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=135; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003476 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=135; total time=   1.7s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=181, n_estimators=249, num_leaves=135; total time=   1.4s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003746 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463[LightGBM] [Info] Start training from score 4.715398\n",
      "\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=242, num_leaves=145; total time=   1.9s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=242, num_leaves=145; total time=   1.9s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003716 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=242, num_leaves=145; total time=   1.7s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=242, num_leaves=145; total time=   1.7s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=231, n_estimators=242, num_leaves=145; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003088 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.3s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.4s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.04, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003146 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003825 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003124 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003430 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.7s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.02, max_depth=182, n_estimators=249, num_leaves=95; total time=   1.2s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003405 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=234, n_estimators=220, num_leaves=145; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=234, n_estimators=220, num_leaves=145; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=234, n_estimators=220, num_leaves=145; total time=   1.6s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003425 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=234, n_estimators=220, num_leaves=145; total time=   1.6s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.045, max_depth=234, n_estimators=220, num_leaves=145; total time=   1.1s\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000964 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1081\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.718463\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005249 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1078\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715398\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=200, num_leaves=90; total time=   1.0s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003551 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.713403\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=200, num_leaves=90; total time=   1.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.003468 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1080\n",
      "[LightGBM] [Info] Number of data points in the train set: 29903, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715920\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=200, num_leaves=90; total time=   1.1s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1083\n",
      "[LightGBM] [Info] Number of data points in the train set: 29904, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715999\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=200, num_leaves=90; total time=   1.2s\n",
      "[CV] END boosting_type=gbdt, learning_rate=0.05, max_depth=191, n_estimators=200, num_leaves=90; total time=   0.8s\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001135 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1091\n",
      "[LightGBM] [Info] Number of data points in the train set: 37379, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
       "              scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
       "                             &#x27;learning_rate&#x27;: [0.02, 0.025, 0.04, 0.045, 0.05],\n",
       "                             &#x27;max_depth&#x27;: array([180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "       193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "       206, 207, 208, 209, 210, 211, 212, 213, 2...\n",
       "       232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "       245, 246, 247, 248, 249]),\n",
       "                             &#x27;n_estimators&#x27;: array([200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "       213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "       226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "       239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249]),\n",
       "                             &#x27;num_leaves&#x27;: array([ 80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130, 135, 140,\n",
       "       145])},\n",
       "              verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;BayesSearchCV<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
       "              scoring=&#x27;neg_root_mean_squared_error&#x27;,\n",
       "              search_spaces={&#x27;boosting_type&#x27;: [&#x27;gbdt&#x27;],\n",
       "                             &#x27;learning_rate&#x27;: [0.02, 0.025, 0.04, 0.045, 0.05],\n",
       "                             &#x27;max_depth&#x27;: array([180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "       193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "       206, 207, 208, 209, 210, 211, 212, 213, 2...\n",
       "       232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "       245, 246, 247, 248, 249]),\n",
       "                             &#x27;n_estimators&#x27;: array([200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "       213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "       226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "       239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249]),\n",
       "                             &#x27;num_leaves&#x27;: array([ 80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130, 135, 140,\n",
       "       145])},\n",
       "              verbose=2)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">estimator: LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">LGBMRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>LGBMRegressor()</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "BayesSearchCV(cv=5, estimator=LGBMRegressor(), n_jobs=-1, random_state=42,\n",
       "              scoring='neg_root_mean_squared_error',\n",
       "              search_spaces={'boosting_type': ['gbdt'],\n",
       "                             'learning_rate': [0.02, 0.025, 0.04, 0.045, 0.05],\n",
       "                             'max_depth': array([180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192,\n",
       "       193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205,\n",
       "       206, 207, 208, 209, 210, 211, 212, 213, 2...\n",
       "       232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244,\n",
       "       245, 246, 247, 248, 249]),\n",
       "                             'n_estimators': array([200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
       "       213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
       "       226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
       "       239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249]),\n",
       "                             'num_leaves': array([ 80,  85,  90,  95, 100, 105, 110, 115, 120, 125, 130, 135, 140,\n",
       "       145])},\n",
       "              verbose=2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos una instancia LGBMRegressor\n",
    "model = lgb.LGBMRegressor()\n",
    "# Establecemos el rango de hiperparametros\n",
    "param_dict = {'boosting_type': ['gbdt'],\n",
    "              'num_leaves': np.arange(80, 150, 5),\n",
    "              'max_depth':np.arange(180, 250, 1),\n",
    "              'learning_rate':[0.02, 0.025, 0.04,0.045,0.05],\n",
    "              'n_estimators': np.arange(200, 250, 1)}\n",
    "\n",
    "# Inicializa el objeto BayesSearchCV\n",
    "opt = BayesSearchCV(\n",
    "    model,\n",
    "    param_dict,\n",
    "    n_iter=50,  # Número de iteraciones de la búsqueda\n",
    "    cv=5,       # Número de divisiones en validación cruzada\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    scoring='neg_root_mean_squared_error',  # Métrica a optimizar\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Realiza la búsqueda bayesiana\n",
    "opt.fit(X_train_final, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros encontrados:\n",
      "OrderedDict([('boosting_type', 'gbdt'), ('learning_rate', 0.04), ('max_depth', 226), ('n_estimators', 249), ('num_leaves', 95)])\n",
      "Mejor puntuación (RMSE) en el conjunto de prueba:\n",
      "0.40774147501482993\n"
     ]
    }
   ],
   "source": [
    "# Imprime los mejores hiperparámetros\n",
    "print(\"Mejores hiperparámetros encontrados:\")\n",
    "print(opt.best_params_)\n",
    "\n",
    "# Mostramos el rendimiento del mejor modelo\n",
    "print(\"Mejor puntuación (RMSE) en el conjunto de prueba:\")\n",
    "print(-1*opt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos el modelo con los mejores hiperparametros \n",
    "model = opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000805 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1091\n",
      "[LightGBM] [Info] Number of data points in the train set: 37379, number of used features: 15\n",
      "[LightGBM] [Info] Start training from score 4.715837\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_final, y_train)\n",
    "# Usamos el modelo final para efectuar las predicciones, reconvirtiendo el resultado a dolares con np.exp\n",
    "y_pred_train = np.exp(model.predict(X_train_final))\n",
    "y_pred_test = np.exp(model.predict(X_test_final))\n",
    "# Reconvertimos a la escala original los valores objetivo reales\n",
    "y_train_euros = np.exp(y_train)\n",
    "y_test_euros = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32476834885039785\n",
      "0.19069646525741102\n"
     ]
    }
   ],
   "source": [
    "# Imprimimos los valores de r**2\n",
    "print(r2_score(y_train_euros,y_pred_train))\n",
    "print(r2_score(y_test_euros,y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.060693008837866\n",
      "31.38902826394113\n"
     ]
    }
   ],
   "source": [
    "# imprimimos los valores del error medio absoluto\n",
    "print(mean_absolute_percentage_error(y_train_euros,y_pred_train)*100)\n",
    "print(mean_absolute_percentage_error(y_test_euros,y_pred_test)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
